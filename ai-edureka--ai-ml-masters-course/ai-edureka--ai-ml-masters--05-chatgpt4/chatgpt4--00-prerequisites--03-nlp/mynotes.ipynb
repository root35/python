{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Text Mining and NLP\n",
    "\n",
    "* Supervised learning\n",
    "* Unsupervised learning (clustering)\n",
    "* Reinforcement learning (learning by experience with penalty/reward)\n",
    "\n",
    "How to find if the learning equation is giving the right prediction -> k-fold training/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading external files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/macbook/python')  # Change directory\n",
    "os.getcwd()  # Get current working directory\n",
    "os.listdir(os.getcwd())\n",
    "\n",
    "os.remove('file/path/here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/macbook/python/ai-edureka--ai-ml-masters-course/ai-edureka--ai-ml-masters--05-chatgpt4/chatgpt4--00-prerequisites--03-nlp')\n",
    "with open('test_file.txt', 'r') as fp_read:\n",
    "    with open('new_file.txt', 'w+') as fp_write:\n",
    "        for line in fp_read:\n",
    "            fp_write.write(line)\n",
    "fp_read.close()\n",
    "fp_write.close()\n",
    "\n",
    "# w+ mode: creates the file if doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-docx\n",
    "import docx\n",
    "document = docx.Document('demo.docx')\n",
    "len(document.paragraphs)\n",
    "document.paragraphs[0].text\n",
    "len(document.paragraphs[0].runs)  # number of words\n",
    "\n",
    "document.save('demo.docx')  # save the updated Word document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "document.add_heading('Title 0', 0)\n",
    "p = document.add_paragraph('A new paragraph having some ')\n",
    "p.add_run('bold ').bold = True\n",
    "p.add_run('and some ')\n",
    "p.add_run('italic').italic = True\n",
    "\n",
    "document.add_heading('Title 1', level=1)\n",
    "\n",
    "document.add_paragraph('Intense quote', style='Intense Quote')\n",
    "document.add_paragraph('First list item', style='List Bullet')\n",
    "document.add_paragraph('First list item', style='List Number')\n",
    "\n",
    "document.add_picture('download.png', width=Inches(1.25))\n",
    "\n",
    "records = (\n",
    "    (3, '101', 'Spam'),\n",
    "    (5, '153', 'Eggs'),\n",
    "    (45, '64', 'Spam and eggs')\n",
    ")\n",
    "\n",
    "table = document.add_table(rows=1, cols=3)\n",
    "header_cells = table.rows[0].cells\n",
    "header_cells[0].text = 'Qty'\n",
    "header_cells[1].text = 'Id'\n",
    "header_cells[2].text = 'Desc'\n",
    "for qty, id, desc in records:\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = str(qty)\n",
    "    row_cells[1].text = id\n",
    "    row_cells[2].text = str(desc)\n",
    "    \n",
    "document.add_page_break()\n",
    "\n",
    "document.save('test.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files and Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('demo.csv')\n",
    "length = len(df)\n",
    "df['new_column'] = pd.Series(np.random.randn(length), index=df.index)\n",
    "df\n",
    "df.to_csv('demo_copy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting, cleaning and pre-processing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing sentence structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
