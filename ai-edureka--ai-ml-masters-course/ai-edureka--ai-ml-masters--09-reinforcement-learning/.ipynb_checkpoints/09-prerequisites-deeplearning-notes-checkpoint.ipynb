{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <H1 style=\"color: black; font-size: 55px;\">Deep Learning</H1>\n",
    " \n",
    " How to train a model:\n",
    " 1. **Model:** layers, activation functions\n",
    " 2. **Loss:** the goal\n",
    " 3. **Optimizer:** how to reach the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01\"></a>\n",
    "<H1 style=\"color: MediumBlue; font-size: 34px; background-color: #E6E6FA; padding: 30px 20px;\">1. Understanding Neural Networks with TensorFlow</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/065.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Tensors</H2>\n",
    "\n",
    "<img src=\"images/066.png\" width=\"600\">\n",
    "<img src=\"images/067.png\" width=\"600\">\n",
    "<img src=\"images/068.png\" width=\"600\">\n",
    "<img src=\"images/069.png\" width=\"600\">\n",
    "<img src=\"images/070.png\" width=\"600\">\n",
    "\n",
    "* `X`: input features\n",
    "* `W`: their weights\n",
    "* `Matmul`*: matrix multiplication between `X` and `W`\n",
    "* `B` add the bias term to the result of matmul\n",
    "* `Relu`: then apply the activation function\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">How it works in TensorFlow</H2>\n",
    "\n",
    "* We define the entire flow\n",
    "* Then we only run the last component: Relu\n",
    "* This last component will go back and calculated the preceding components in the backend\n",
    "\n",
    "<img src=\"images/070.png\" width=\"600\">\n",
    "<img src=\"images/071.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.6\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.7.3 (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.7.3\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow==2.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f():\n",
    "    constant = tf.constant('hello')\n",
    "    print(constant)\n",
    "    tf.print(constant)\n",
    "f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">3 types of data</H2>\n",
    "\n",
    "<H3 style=\"color: MediumBlue; font-size: 17px;\">Constant</H3>\n",
    "\n",
    "Unchangeable value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "3 4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(3.0, tf.float32)\n",
    "b = tf.constant(4.0)                  # also tf.float32 implicitly\n",
    "print(a)\n",
    "print(b)\n",
    "tf.print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.0, shape=(), dtype=float32)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "c = a * b\n",
    "print(c)\n",
    "tf.print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3 style=\"color: MediumBlue; font-size: 17px;\">Placeholder</H3>\n",
    "\n",
    "A promise to provide a value later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3 style=\"color: MediumBlue; font-size: 17px;\">Variable</H3>\n",
    "\n",
    "Add trainable parameters to a graph\n",
    "[Variable documentation](https://www.tensorflow.org/api_docs/python/tf/Variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3 style=\"color: MediumBlue; font-size: 17px;\">TensorFlow Math</H3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.add(5, 2)\n",
    "x = tf.subtract(5, 10)\n",
    "x = tf.multiply(9, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3 style=\"color: MediumBlue; font-size: 17px;\">Converting data types</H3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Activation Functions</H2>\n",
    "\n",
    "<img src=\"images/072.png\" width=\"650\">\n",
    "\n",
    "<img src=\"images/073.png\" width=\"650\">\n",
    "\n",
    "Sigmo√Ød: predicts a probability for each class\n",
    "\n",
    "<img src=\"images/074.png\" width=\"650\">\n",
    "\n",
    "<img src=\"images/075.png\" width=\"650\">\n",
    "\n",
    "<img src=\"images/076.png\" width=\"650\">\n",
    "\n",
    "ReLu: derives the most intelligent weights in a Neural Network\n",
    "\n",
    "<img src=\"images/077.png\" width=\"650\">\n",
    "\n",
    "Softmax: predicts a probability for each class, they sum up to 1    \n",
    "\n",
    "Works well with classes more than 2\n",
    "\n",
    "<img src=\"images/078.png\" width=\"650\">\n",
    "\n",
    "<H3 style=\"color: MediumBlue; font-size: 17px;\">--</H3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310585786300049\n",
      "0.8807970779778823\n",
      "0.9820137900379085\n",
      "0.5\n",
      "0.9933071490757153\n",
      "0.0024726231566347743\n",
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid_(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "x = [1, 2, 4, 0, 5, -6, 7]\n",
    "for a in x:\n",
    "    print(sigmoid_(a))\n",
    "    \n",
    "# If the value is bigger, it will be closer to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh(a) = (e^a - e^-a) / e^a + e^-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.999329299739067\n",
      "-0.9640275800758169\n",
      "0.0\n",
      "0.9640275800758169\n",
      "0.999329299739067\n"
     ]
    }
   ],
   "source": [
    "def tanh_(a):\n",
    "    return np.tanh(a)\n",
    "x = [-4, -2, 0, 2, 4]\n",
    "for a in x:\n",
    "    print(tanh_(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def relu_(a):\n",
    "    return np.maximum(0, a)  # relu: returns 0 if a < 0\n",
    "x = [-4, -2, 2, 4]\n",
    "for a in x:\n",
    "    print(relu_(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.82005792e-01 1.79860635e-02 8.14457845e-06]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = [12, 8, .3]\n",
    "def softmax_(a):\n",
    "    return np.exp(a) / np.sum(np.exp(a), axis = 0)\n",
    "print(softmax_(scores))\n",
    "print(sum(softmax_(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = [.2, 1, 0, 3, -2]\n",
    "sigmoid_activation = tf.sigmoid(a)\n",
    "tanh_activation = tf.tanh(a)\n",
    "relu_activation = tf.nn.relu(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">OneHot encoding</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [1,2, 3, 1, 2]\n",
    "# 1 = [1, 0, 0]\n",
    "# 2 = [0, 1, 0]\n",
    "# 3 = [0, 0, 1]\n",
    "\n",
    "Y = [0, 1, 1, 0, 1, 1, 0]\n",
    "# 0 = [1, 0]\n",
    "# 1 = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Initializing weights</H2>\n",
    "\n",
    "In NNs, always initialize weights with some random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'truncated_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-45b5f7119468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Normally distributed numbers with mean 0 and std dev 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# All numbers generated from this normal distribution will be from +/- 2 std.dev   => no extreme values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'truncated_normal'"
     ]
    }
   ],
   "source": [
    "a = tf.truncated_normal([2, 3])\n",
    "# Normally distributed numbers with mean 0 and std dev 1\n",
    "# All numbers generated from this normal distribution will be from +/- 2 std.dev   => no extreme values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01\"></a>\n",
    "<H1 style=\"color: MediumBlue; font-size: 34px; background-color: #E6E6FA; padding: 30px 20px;\">2. Deep Dive into Neural Networks with TensorFlow</H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">How a perceptron learns</H2>\n",
    "\n",
    "<img src=\"images/079.png\" width=\"600\">\n",
    "<img src=\"images/080.png\" width=\"600\">\n",
    "<img src=\"images/081.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Perceptron examples</H2>\n",
    "\n",
    "<img src=\"images/082.png\" width=\"600\">\n",
    "<img src=\"images/083.png\" width=\"600\">\n",
    "<img src=\"images/084.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Training a perceptron</H2>\n",
    "\n",
    "<img src=\"images/085.png\" width=\"600\">\n",
    "<img src=\"images/087.png\" width=\"600\">\n",
    "<img src=\"images/088.png\" width=\"600\">\n",
    "<img src=\"images/089.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">The loss function</H2>\n",
    "\n",
    "Measures how far apart the current model is from the provided data\n",
    "\n",
    "= How good or bad the model is doing\n",
    "\n",
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">The optimization function</H2>\n",
    "\n",
    "Updates each variable according to the magnitude of the derivative of loss with respect to that variable\n",
    "= The CORE of learning\n",
    "= Updating the weights in a way that minimizes the loss\n",
    "  \n",
    "Convex function have only one possible minimum value = the *global minimum*\n",
    "If the curve is more bumpy, we can see *local minima* (creux entre 2 valeurs)\n",
    "\n",
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">The learning rate</H2>\n",
    "\n",
    "One of the most important hyperparameters\n",
    "\n",
    "Find one that reaches the minimum in a small number of steps\n",
    "\n",
    "Model divergence: oscillating between , never reaching the minimum\n",
    "\n",
    "Too small steps + not enough epochs -> risk of never reaching the minimum\n",
    "\n",
    "<img src=\"images/090.png\" width=\"600\">\n",
    "<img src=\"images/091.png\" width=\"600\">\n",
    "<img src=\"images/092.png\" width=\"600\">\n",
    "<img src=\"images/093.png\" width=\"600\">\n",
    "<img src=\"images/094.png\" width=\"600\">\n",
    "<img src=\"images/095.png\" width=\"600\">\n",
    "<img src=\"images/096.png\" width=\"600\">\n",
    "\n",
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">TensorFlow implementation</H2>\n",
    "\n",
    "<img src=\"images/097.png\" width=\"600\">\n",
    "<img src=\"images/098.png\" width=\"600\">\n",
    "<img src=\"images/099.png\" width=\"600\">\n",
    "<img src=\"images/100.png\" width=\"600\">\n",
    "<img src=\"images/101.png\" width=\"600\">\n",
    "<img src=\"images/102.png\" width=\"600\">\n",
    "<img src=\"images/103.png\" width=\"600\">\n",
    "<img src=\"images/104.png\" width=\"600\">\n",
    "<img src=\"images/105.png\" width=\"600\">\n",
    "<img src=\"images/106.png\" width=\"600\">\n",
    "<img src=\"images/107.png\" width=\"600\">\n",
    "<img src=\"images/108.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01\"></a>\n",
    "<H1 style=\"color: MediumBlue; font-size: 34px; background-color: #E6E6FA; padding: 30px 20px;\">3. Master Deep Networks</H1>\n",
    "\n",
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Introduction</H2>\n",
    "\n",
    "Single perceptron is a linear classifier -> cannot solve a XOR problem\n",
    "\n",
    "<img src=\"images/109.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Limitations of a Single Perceptron</H2>\n",
    "\n",
    "<img src=\"images/110.png\" width=\"600\">\n",
    "<img src=\"images/111.png\" width=\"600\">\n",
    "<img src=\"images/112.png\" width=\"600\">\n",
    "\n",
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Multiple Neurons</H2>\n",
    "\n",
    "Our role as Machine Learning Engineers:   \n",
    "How to make the nodes in the **hidden layers as intelligent as possible**,   \n",
    "so that they can **find the features** in the input layer,   \n",
    "and **calculate interactions** of these features   \n",
    "with the help of **weights** and **activation functions** to improve the model\n",
    "-> Representation Learning = creating a representation of the input nodes into the hidden nodes\n",
    "\n",
    "  \n",
    "In the **single perceptron**, we are making **predictions from the input features**   \n",
    "In the **multiple perceptron**, we are making **predictions from the hidden layers**\n",
    "\n",
    "<img src=\"images/113.png\" width=\"600\">\n",
    "<img src=\"images/114.png\" width=\"600\">\n",
    "<img src=\"images/115.png\" width=\"600\">\n",
    "<img src=\"images/116.png\" width=\"600\">\n",
    "<img src=\"images/117.png\" width=\"600\">\n",
    "\n",
    "Artificial Neural Network (ANN) = \"artificial\" because only one hidden layer\n",
    "\n",
    "<img src=\"images/118.png\" width=\"600\">\n",
    "\n",
    "**INPUT LAYER** =\n",
    "* one node for each feature\n",
    "* '+ 1 node for the bias term\n",
    "\n",
    "**ARCHITECTURE** of a deep neural network:\n",
    "* number of hidden layers\n",
    "* number of nodes in each hidden layer (each layer can have a different number of nodes)\n",
    "* types of connections between layers\n",
    "\n",
    "**IMPORTANT!**   \n",
    "More hidden layers -> helping in identifying more features:    \n",
    "* because the more nodes you have, the more features you are calculating\n",
    "* and the more features you have, the model will be predicting better results\n",
    "\n",
    "BUT, if problem not very complex, if too much nodes, most of them will be 0   \n",
    "-> more computing power than required\n",
    "\n",
    "**STRATEGY**: \n",
    "* define a simple architecture\n",
    "* then add nodes in layers, and add layers\n",
    "* and see if it improves the accuracy\n",
    "\n",
    "**OUTPUT LAYER**: size = number of classes predicted\n",
    "\n",
    "<img src=\"images/119.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01-01\"></a>\n",
    "<H2 style=\"color: MediumBlue; font-size: 21px; background-color: #F0F8FF; padding: 15px 20px;\">Working with Deep Networks</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/120.png\" width=\"600\">\n",
    "   \n",
    "1. nodes(layer n+1) = activation[matmul(nodes(layer n) * weights) + bias term]\n",
    "    - **weights:** randomly initiated\n",
    "    - **bias term:** randomly initiated\n",
    "    - **activation function:** most of the time ReLu or Sigmoid\n",
    "    - each node in the hidden layer is kind of a perceptron\n",
    "    - each node in layer n+1 is a combination of all the nodes in layer n\n",
    "    - nodes in each layer are not connected with each other\n",
    "    - **Dense layer**: **every** node in layer n is connected with **every** node in layer n+1\n",
    "    - NN starts with random weights -> no intelligence in the forward propagation    \n",
    "    \n",
    "2. The intelligence comes from the **backpropagation**:\n",
    "    - calculate the difference between (actual - predicted)   \n",
    "      then backpropagate this error in the layer to adjust all the weights    \n",
    "      in the direction so that the error is minimized = weights closer to actual expected output\n",
    "    - epoch = \n",
    "        - one forward > calculate total error > one backward\n",
    "        - nb epochs = how many times we do the forward and backward pass\n",
    "    - derivative, chain rule...: more details in the video\n",
    "\n",
    "Rule of thumb for number of nodes in a hidden layer as a starting point:\n",
    "    square root(nb input nodes + nb output nodes)\n",
    "BUT more always a good idea for better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/121.png\" width=\"600\">\n",
    "<img src=\"images/122.png\" width=\"600\">\n",
    "<img src=\"images/123.png\" width=\"600\">\n",
    "<img src=\"images/124.png\" width=\"600\">\n",
    "<img src=\"images/125.png\" width=\"600\">\n",
    "<img src=\"images/126.png\" width=\"600\">\n",
    "<img src=\"images/127.png\" width=\"600\">\n",
    "<img src=\"images/128.png\" width=\"600\">\n",
    "<img src=\"images/129.png\" width=\"600\">\n",
    "<img src=\"images/130.png\" width=\"600\">\n",
    "<img src=\"images/131.png\" width=\"600\">\n",
    "<img src=\"images/132.png\" width=\"600\">\n",
    "<img src=\"images/133.png\" width=\"600\">\n",
    "<img src=\"images/134.png\" width=\"600\">\n",
    "<img src=\"images/135.png\" width=\"600\">\n",
    "<img src=\"images/136.png\" width=\"600\">\n",
    "truncated_normal: generate matrix with random numbers  \n",
    "with 0 mean and 1 std. dev. (= normaly distributed)\n",
    "all values between 0 and +/- 1 std.dev.\n",
    "<img src=\"images/137.png\" width=\"600\">\n",
    "<img src=\"images/138.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"01\"></a>\n",
    "<H1 style=\"color: MediumBlue; font-size: 34px; background-color: #E6E6FA; padding: 30px 20px;\">4. Convolutional Neural Networks (CNN)</H1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
