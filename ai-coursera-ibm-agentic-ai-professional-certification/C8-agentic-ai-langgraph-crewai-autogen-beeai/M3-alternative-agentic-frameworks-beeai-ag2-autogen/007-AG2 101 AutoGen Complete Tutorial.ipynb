{"cells":[{"cell_type":"markdown","id":"491d5759-7e1f-49c8-a107-9bb367cb909e","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"c4c190cd-c78f-464a-9efb-b33fd40f4800","metadata":{},"outputs":[],"source":["# AG2 101 (AutoGen): Complete Tutorial\n","\n","Estimated time needed: **45** minutes\n","\n","This notebook provides a comprehensive guide to AG2 (formerly AutoGen) basic concepts with runnable examples and detailed explanations. AG2 is an open-source programming framework for building AI agents and facilitating cooperation among multiple agents to solve tasks.\n","\n","## Table of Contents\n","\n","<ol>\n","    <li><a href=\"#Setup-and-Import\">Setup and Import</a></li>\n","    <li><a href=\"#Configure-API-Keys\">Configure API Keys</a></li>\n","    <li>\n","        <a href=\"#Introduction-to-Agent-Concepts\">Introduction to Agent Concepts</a>\n","        <ol>\n","            <li><a href=\"#Conversable-Agent\">Conversable Agent</a></li>\n","            <li><a href=\"#Creating-Specialized-Agents\">Creating Specialized Agents</a></li>\n","            <li><a href=\"#Built-in-Agent-Types\">Built-in Agent Types</a></li>\n","        </ol>\n","    </li>\n","    <li><a href=\"#Human-in-the-Loop\">Human-in-the-Loop</a></li>\n","    <li>\n","        <a href=\"#Agent-Orchestration-&-Multi-Agent-Systems-in-AG2\">Agent Orchestration & Multi-Agent Systems in AG2</a>\n","        <ol>\n","            <li><a href=\"#GroupChat-and-GroupChatManager\">GroupChat and GroupChatManager</a></li>\n","        </ol>\n","    </li>\n","    <li><a href=\"#Tools-and-Extensions\">Tools and Extensions</a></li>\n","    <li><a href=\"#Structured-Outputs\">Structured Outputs</a></li>\n","    <li><a href=\"#Best-Practices\">Best Practices</a></li>\n","    <li><a href=\"#Conclusion\">Conclusion</a></li>\n","    <li><a href=\"#Authors\">Authors</a></li>\n","    \n","</ol>\n"]},{"cell_type":"markdown","id":"030c4a9a-6f3c-40cb-b9ff-4b4151ce78a7","metadata":{},"outputs":[],"source":["## Setup and Import\n","\n","Here we install AG2, import the required modules, and load the environment variables.  \n"]},{"cell_type":"code","id":"c3f6d35c-9df5-4635-a9af-2dfb4a97afad","metadata":{},"outputs":[],"source":["!pip install ag2[openai] python-dotenv | tail -n 1"]},{"cell_type":"code","id":"7f85c38b-eccd-4408-b0fd-3a08e8743c46","metadata":{},"outputs":[],"source":["# Import necessary modules\nimport os\nfrom dotenv import load_dotenv\nfrom autogen import ConversableAgent, AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\nfrom autogen.llm_config import LLMConfig\nimport json\nimport time\nimport random\n\n# Load environment variables\nload_dotenv()\n\nprint(\"AG2 modules imported successfully!\")"]},{"cell_type":"code","id":"cdeaf80f-7be1-4454-af5c-d898677cdbbc","metadata":{},"outputs":[],"source":["import logging\n\n# Suppress API key format warning\nlogging.getLogger(\"autogen.oai.client\").setLevel(logging.ERROR)"]},{"cell_type":"markdown","id":"3d82f079-6649-4903-a9a6-5c87388c906a","metadata":{},"outputs":[],"source":["### Configure API Keys\n","\n","Autogen supports various LLM providers. Let's set up configuration for OpenAI.  \n","\n","**Note:** In this environment, you do not need to run this cell and you can skip to the next section. \n"]},{"cell_type":"code","id":"406eb501-f6d8-40a6-8a94-dbba8aff4401","metadata":{},"outputs":[],"source":["# # Create a configuration file for your API keys\n# # Replace with your actual API key\n# config_list = [\n#     {\n#         \"model\": \"gpt-4\",\n#         #\"api_key\": \"\"\n#     }\n# ]\n\n# Alternatively, you can create a JSON file\n# '''\n# with open('config.json', 'w') as f:\n#    json.dump(config_list, f)\n    \n# Then load it\n# config_list = config_list_from_json(\"config.json\")\n# '''"]},{"cell_type":"markdown","id":"3bd82219-00e5-4ad1-bede-7e618de36823","metadata":{},"outputs":[],"source":["## Introduction to Agent Concepts\n","\n","We have several agent concepts in AG2 to help you build your AI agents. We introduce the most common ones here:\n","\n","- **Conversable agent**: Agents that are able to send messages, receive messages and generate replies using GenAI models, non-GenAI tools, or human inputs.\n","\n","- **Human in the loop**: Add human input to the conversation.\n","\n","- **Orchestrating multiple agents**: Users can orchestrate multiple agents with built-in conversation patterns such as swarms, group chats, nested chats, sequential chats or customize the orchestration by registering custom reply methods.\n","\n","- **Tools**: Programs that can be registered, invoked and executed by agents.\n","\n","- **Advanced concepts**: AG2 supports more concepts such as structured outputs, RAG, code execution, and so on.\n"]},{"cell_type":"markdown","id":"486ac411-4b8f-475a-b3d9-1e3f16ce8dd2","metadata":{},"outputs":[],"source":["### Conversable Agent\n","\n","The ConversableAgent is the fundamental building block of AG2, designed to enable seamless communication between AI entities. This core agent type handles message exchange and response generation, serving as the base class for all agents in the framework.\n","\n","#### Key characteristics:\n","- **Communication**: Can send and receive messages\n","- **Processing**: Handles information and generates responses\n","- **Personality**: Defined by system messages\n","- **Flexibility**: Base for all other agent types\n","\n","In the example below, we'll create a simple information validation workflow with two specialized agents that communicate with each other.\n","\n","**Note**: `initiate_chat()` starts a conversation with another agent.\n"]},{"cell_type":"code","id":"f914d663-c1d4-4e39-8ccd-7637233a2135","metadata":{},"outputs":[],"source":["from autogen import ConversableAgent, LLMConfig\n\n# Step 1: Define the LLM configuration\nllm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n\n# Step 2: Define our two agents ‚Äî a student and a tutor\nwith llm_config:\n    # Create the student agent (asks questions)\n    student = ConversableAgent(\n        name=\"student\",\n        system_message=\"You are a curious student. You ask clear, specific questions to learn new concepts.\",\n        human_input_mode=\"NEVER\"  # disables manual input during chat\n    )\n\n    # Create the tutor agent (responds with beginner-friendly answers)\n    tutor = ConversableAgent(\n        name=\"tutor\",\n        system_message=\"You are a helpful tutor who provides clear and concise explanations suitable for a beginner.\",\n        human_input_mode=\"NEVER\"\n    )\n\n# Step 3: Start a 2-turn conversation initiated by the student\nchat_result = student.initiate_chat(\n    recipient=tutor,                                # who the student is talking to\n    message=\"Can you explain what a neural network is?\",  # the student's question\n    max_turns=2,                                     # total number of back-and-forth messages\n    summary_method=\"reflection_with_llm\"            # generate a final summary using LLM\n)\n\n# Step 4: Print the summary of the conversation\nprint(\"\\nFinal Summary:\")\nprint(chat_result.summary)\n"]},{"cell_type":"markdown","id":"c5689ee1-f637-435d-a979-6af48ef83d26","metadata":{},"outputs":[],"source":["#### Why Add summary_method=`\"reflection_with_llm\"`?\n","\n","By enabling summary_method=`\"reflection_with_llm\"`, we allow the system to generate a final response that is not simply a direct answer, but a **reflection of a structured conversation** between multiple agents with defined roles.\n","\n","In this case, instead of prompting an LLM directly with *‚ÄúWhat is a neural network?‚Äù*, the system simulates a conversation where:\n","- A **student** asks a clear question,\n","- A **tutor** responds with a beginner-friendly explanation,\n","- And the LLM reflects on this interaction to generate a detailed and coherent summary.\n","  \n","This approach can also be extended to **solve complex tasks** by simulating a structured conversation between **expert agents** (for example, a data scientist, a software engineer, and a business strategist), each contributing from their expertise to build a better solution.\n","\n","This often produces **higher-quality, context-rich answers**, as the reasoning is distributed and clarified through role-based collaboration.  \n","\n","**Note:** You can try running the conversation without adding the line `summary_method=\"reflection_with_llm\"` and see the difference. \n"]},{"cell_type":"markdown","id":"b577acef-ce09-4cdc-8072-75ba0d6ce0b9","metadata":{},"outputs":[],"source":["## Creating Specialized Agents\n","\n","The power of ConversableAgent comes from customization. Let's create agents with different personalities and purposes:\n"]},{"cell_type":"code","id":"41f6239d-3d75-4657-b7bb-045682e4a653","metadata":{},"outputs":[],"source":["# Create a Technical Expert Agent\ntech_expert = ConversableAgent(\n    name=\"tech_expert\",\n    system_message=\"\"\"You are a senior software engineer with expertise in Python, AI, and system design.\n    Provide technical, detailed explanations with code examples when appropriate.\n    Always consider best practices and performance implications.\"\"\",\n    llm_config=llm_config,\n    human_input_mode=\"NEVER\"\n)\n\n# Create a Creative Writer Agent\ncreative_writer = ConversableAgent(\n    name=\"creative_writer\",\n    system_message=\"\"\"You are a creative writer and storyteller.\n    Your responses are engaging, imaginative, and use vivid descriptions.\n    You excel at making complex topics accessible through stories and analogies.\"\"\",\n    llm_config=llm_config,\n    human_input_mode=\"NEVER\"\n)\n\n# Create a Business Analyst Agent\nbusiness_analyst = ConversableAgent(\n    name=\"business_analyst\",\n    system_message=\"\"\"You are a business analyst focused on ROI, efficiency, and strategic planning.\n    Always consider business impact, costs, and practical implementation.\n    Provide actionable recommendations with clear metrics.\"\"\",\n    llm_config=llm_config,\n    human_input_mode=\"NEVER\"\n)\n\nagents = [tech_expert, creative_writer, business_analyst]\nprint(\"Specialized agents created!\")\nfor agent in agents:\n    print(f\"- {agent.name}: {agent.system_message.split('.')[0]}.\")"]},{"cell_type":"markdown","id":"b76000e1-7902-4dea-9086-5061bd60be00","metadata":{},"outputs":[],"source":["## Built-in Agent Types\n","\n","AG2 provides specialized agent classes built on `ConversableAgent` to streamline common workflows such as task-solving, tool use, and user interaction.\n","\n","#### AssistantAgent ‚Äî Task-solving LLM assistant\n","\n","`AssistantAgent` is a subclass of `ConversableAgent` configured with a default system message tailored for solving tasks using LLMs. It can suggest Python code blocks, offer debugging suggestions, and provide structured responses.\n","\n","- `human_input_mode`: Defaults to `\"NEVER\"` ‚Äî the assistant operates autonomously.\n","- `code_execution_config`: Defaults to `False` ‚Äî it does **not execute code** itself.\n","- Designed to work collaboratively with other agents (for example, `UserProxyAgent`) that handle execution.\n","\n","This agent excels at reasoning, planning, and generating code ‚Äî and expects others to handle the execution layer.\n","\n","#### UserProxyAgent ‚Äî Executing code on behalf of the user\n","\n","`UserProxyAgent` is a subclass of `ConversableAgent` that acts as a proxy for the human user. It is designed to **execute code**, simulate user decisions, and provide execution-based feedback to other agents like `AssistantAgent`.\n","\n","- `human_input_mode`: Defaults to `\"ALWAYS\"` ‚Äî prompts the user at every turn.\n","- `llm_config`: Defaults to `False` ‚Äî no LLM responses unless explicitly configured.\n","- **Code execution is enabled by default.**\n","\n","You can customize its behavior by:\n","- Registering an auto-reply function via `.register_reply()`.\n","- Overriding `.get_human_input()` to change how user input is gathered.\n","- Overriding `.execute_code_blocks()`, `.run_code()`, or `.execute_function()` to control code execution behavior.\n","\n","These two agents are often paired: the `AssistantAgent` writes code, and the `UserProxyAgent` executes it.\n"]},{"cell_type":"code","id":"11e70598-cdfc-46bd-82fe-9e00a4536df8","metadata":{},"outputs":[],"source":["# %%\n# Requirements:\n# !pip install matplotlib numpy  # first run without installing the libraries and see if the agent installs the required libraries itself.\n\nfrom autogen import AssistantAgent, UserProxyAgent, LLMConfig\nfrom autogen.coding import LocalCommandLineCodeExecutor\n\n# Step 1: Configure the LLM to use (e.g., GPT-4o Mini via OpenAI)\nllm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n\n# Step 2: Create the assistant agent (code-writing AI)\nwith llm_config:\n    assistant = AssistantAgent(\n        name=\"assistant\",\n        system_message=\"You are a helpful assistant who writes and explains Python code clearly.\"\n    )\n\n# Step 3: Create the user agent that can execute code\nuser_proxy = UserProxyAgent(\n    name=\"user_proxy\",\n    human_input_mode=\"NEVER\",  # Automatically executes code without human input\n    max_consecutive_auto_reply=5,  # Ends after 5 response cycles (assistant + user_proxy turns)\n    code_execution_config={\n        \"executor\": LocalCommandLineCodeExecutor(work_dir=\"coding\", timeout=30),\n    },\n)\n\n# Step 4: Start a simple task that leads to code generation and execution\nchat_result = user_proxy.initiate_chat(\n    recipient=assistant,\n    message=\"\"\"Plot a sine wave using matplotlib from -2œÄ to 2œÄ and save the plot as sine_wave.png.\"\"\",\n    max_turns=4,  # 2 rounds of assistant ‚Üî user_proxy\n    summary_method=\"reflection_with_llm\"  # Optional: final LLM-generated summary\n)\n\n# Step 5: Display the generated figure (optional for notebook environments)\nfrom IPython.display import Image, display\nimport os\n\nimage_path = \"coding/sine_wave.png\"\nif os.path.exists(image_path):\n    display(Image(filename=image_path))\nelse:\n    print(\"Plot not found. Please check if the assistant saved the file correctly.\")\n\n# Step 6: Print summary\nprint(\"\\n Final Summary:\")\nprint(chat_result.summary)\n"]},{"cell_type":"markdown","id":"9d8a8e07-8dfc-4b2b-94b3-a55fbc239178","metadata":{},"outputs":[],"source":["## Human-in-the-Loop\n","\n","AG2 makes integrating human feedback seamless through its human-in-the-loop functionality, allowing AI agents to collaborate with humans during workflows.  \n","\n","This is crucial for:   \n","\n","- **Critical decisions** requiring human judgment\n","- **High-stakes scenarios** with significant consequences\n","- **Regulatory compliance** requiring human oversight\n","- **Quality assurance** and validation\n","\n","You can configure how and when human input is solicited using the `human_input_mode` parameter:\n","\n","- ALWAYS: Requires human input for every response\n","\n","- NEVER: Operates autonomously without human involvement\n","\n","- TERMINATE: Only requests human input to end conversations\n","\n","For convenience, AG2 provides the specialized `UserProxyAgent` class that automatically sets `human_input_mode` to ALWAYS and supports **code execution**. \n","\n","**important note**: Always use code execution functionality with caution and at your own discretion.\n"]},{"cell_type":"markdown","id":"a34261c0-215f-4b75-977f-198dd5e6e3a2","metadata":{},"outputs":[],"source":["### Human-in-the-Loop Example: Bug Triage Bot\n","\n","This example demonstrates how to use AG2‚Äôs `ConversableAgent` in `human_input_mode=\"ALWAYS\"` to enable **human-in-the-loop workflows**.\n","\n","We simulate a **bug triage assistant** (`triage_bot`) that classifies bug reports as either:\n","- Escalate (for example, critical crash or security issue),\n","- Close (for example, minor cosmetic issue),\n","- Medium priority (default for others).\n","\n","For each classification, the assistant **asks the human agent for confirmation or correction**. This ensures the AI doesn‚Äôt act on high-impact decisions without oversight.\n","\n","At the end, the assistant summarizes the triage results.\n","\n","---\n","\n","### Try these inputs when prompted\n","\n","When you‚Äôre prompted to reply as the human agent, try responding with the following:\n","\n","- **Confirm assistant‚Äôs suggestion**  \n","  `\"Yes, escalate it.\"`  \n","  `\"Closing this makes sense.\"`\n","\n","- **Override assistant‚Äôs suggestion**  \n","  `\"This should be marked as high priority instead.\"`  \n","  `\"Let‚Äôs keep this open for now.\"`\n","\n","- **Ask for clarification**  \n","  `\"Why do you think this is low priority?\"`  \n","  `\"Can you provide more reasoning?\"`\n","\n","You can also type `exit` at any time to end the conversation.\n"]},{"cell_type":"code","id":"a2d00c0f-67f0-4e47-b381-8ad6ca229c3d","metadata":{},"outputs":[],"source":["from autogen import ConversableAgent, LLMConfig\nimport os\nimport random\n\n\n# Step 1: Configure the LLM to use (e.g., GPT-4o Mini via OpenAI)\nllm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n\n# Step 2: Define system message for bug triage assistant\ntriage_system_message = \"\"\"\nYou are a bug triage assistant. You will be given bug report summaries.\n\nFor each bug:\n- If it is urgent (e.g., 'crash', 'security', or 'data loss' is mentioned), escalate it and ask the human agent for confirmation.\n- If it seems minor (e.g., cosmetic, typo), suggest closing it but still ask for human review.\n- Otherwise, classify it as medium priority and ask the human for review.\n\nOnce all bugs are processed, summarize what was escalated, closed, or marked as medium priority.\nEnd by saying: \"You can type exit to finish.\"\n\"\"\"\n\n# Step 3: Create the assistant agent\nwith llm_config:\n    triage_bot = ConversableAgent(\n        name=\"triage_bot\",\n        system_message=triage_system_message,\n    )\n\n# Step 4: Create the human agent who will review each recommendation\nhuman = ConversableAgent(\n    name=\"human\",\n    human_input_mode=\"ALWAYS\",  # prompts for input at each step\n)\n\n# Step 5: Generate sample bug reports\nBUGS = [\n    \"App crashes when opening user profile.\",\n    \"Minor UI misalignment on settings page.\",\n    \"Password reset email not sent consistently.\",\n    \"Typo in the About Us footer text.\",\n    \"Database connection timeout under heavy load.\",\n    \"Login form allows SQL injection attack.\",\n]\n\nrandom.shuffle(BUGS)\nselected_bugs = BUGS[:3]\n\n# Format the initial task\ninitial_prompt = (\n    \"Please triage the following bug reports one by one:\\n\\n\" +\n    \"\\n\".join([f\"{i+1}. {bug}\" for i, bug in enumerate(selected_bugs)])\n)\n\n# Step 6: Start the conversation\nresponse = human.run(\n    recipient=triage_bot,\n    message=initial_prompt,\n)\n\n# Step 7: Display the response\nresponse.process()\n"]},{"cell_type":"markdown","id":"d57dbc1f-2b56-4a91-8eba-4d75aff1d878","metadata":{},"outputs":[],"source":["## Agent Orchestration & Multi-Agent Systems in AG2<a name=\"agent-orchestration\"></a>\n","\n","AG2 enables the coordination of multiple intelligent agents to collaboratively solve complex tasks. This is known as **agent orchestration** ‚Äî a powerful design pattern where each agent plays a specialized role, and a **group manager** handles the conversation flow.\n","\n","### Why Multi-Agent Systems?\n","\n","Many real-world problems require more than just a single AI assistant. With AG2, you can:\n","\n","- Assign specific roles and responsibilities to different agents.\n","- Orchestrate conversations using built-in patterns (for example, Auto, RoundRobin, Manual).\n","- Enable agents to build on each other's outputs and refine ideas.\n","- Incorporate human agents for oversight, decisions, or approval.\n","\n","### Orchestration Patterns in AG2\n","\n","AG2 provides several orchestration patterns to structure agent interactions:\n","\n","- **Two-Agent Chat**: Simple back-and-forth between two agents.\n","- **Sequential Chat**: Conversations where one agent‚Äôs output becomes another‚Äôs input.\n","- **Group Chat**: Multiple agents interact, with selection logic for who speaks next.\n","- **Nested Chat**: Reusable sub-conversations packaged as a single workflow.\n","\n","---\n","\n","## GroupChat and GroupChatManager\n","\n","In AG2, multi-agent collaboration is coordinated using `GroupChat` and `GroupChatManager`.\n","\n","### GroupChat\n","\n","`GroupChat` defines a team of agents and how they interact in a shared conversation. It includes:\n","\n","- **Agents**: A list of AI (or human) agents that participate in the group dialogue.\n","- **Speaker Selection Method**: Determines which agent speaks next. Options include:\n","  - `\"auto\"`: Uses the LLM to select the most contextually appropriate agent.\n","  - `\"round_robin\"`: Agents take turns in a fixed sequence.\n","  - `\"manual\"`: Human selects the next speaker.\n","  - `\"random\"`: Agents are chosen randomly.\n","\n","This structure allows you to define collaborative workflows where agents build on each other‚Äôs contributions.\n","\n","### GroupChatManager\n","\n","`GroupChatManager` is responsible for managing the flow of the group conversation and it:\n","\n","- Orchestrates message passing between agents.\n","- Decides when to stop the conversation (for example, based on a termination condition or turn limit).\n","- Leverages the speaker selection method defined in `GroupChat`.\n","\n","It acts like a facilitator that ensures the conversation runs according to the logic you've configured.\n","\n","### How It Works\n","\n","1. A conversation is initiated by one of the agents (often a user or teacher agent).\n","2. The `GroupChatManager` uses the selected pattern (for example, AutoPattern) to determine which agent speaks next.\n","3. Agents take turns responding based on their roles and system messages.\n","4. The conversation ends either when a stop condition (for example, a message like \"DONE\") is met or when a maximum number of turns is reached.\n","\n","This setup enables modular, role-based collaboration ‚Äî ideal for use cases like lesson planning, research workflows, or multi-perspective decision-making.\n","\n","To explore more orchestration patterns, visit the AG2 documentation at:  \n","https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/orchestration/group-chat/introduction/\n","\n","---\n","\n","### Example: Group Chat for Lesson Planning\n","\n","This example shows how a teacher agent collaborates with a planner and a reviewer to create a lesson plan, using AG2‚Äôs `GroupChat` and `AutoPattern` to manage the conversation.\n","\n","**Note:** The `is_termination_msg` parameter used for `teacher` agent defines a custom rule to end the conversation ‚Äî  \n","in this case, the workflow stops when the teacher replies with \"DONE!\".\n"]},{"cell_type":"code","id":"3ec4e961-c5a2-41d0-b299-cf91a5402fb4","metadata":{},"outputs":[],"source":["from autogen import ConversableAgent, GroupChat, GroupChatManager, LLMConfig\n\n# Replace \"PLACEHOLDER\" with your actual OpenAI API key if running locally\nllm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\", )  # add api_key=\"PLACE_HOLDER\" Replace with your API key to run outside this learning environment\n\n# Define system messages and agent descriptions\nplanner_message = \"Create a short lesson plan for 4th graders.\"\nreviewer_message = \"Review a plan and suggest up to 3 brief edits.\"\nteacher_message = \"Suggest a topic and reply DONE when satisfied.\"\n\nwith llm_config:\n    lesson_planner = ConversableAgent(\n        name=\"planner_agent\",\n        system_message=planner_message,\n        description=\"Makes lesson plans.\",\n    )\n\n    lesson_reviewer = ConversableAgent(\n        name=\"reviewer_agent\",\n        system_message=reviewer_message,\n        description=\"Reviews lesson plans and suggests edits.\",\n    )\n\n    teacher = ConversableAgent(\n        name=\"teacher_agent\",\n        system_message=teacher_message,\n        is_termination_msg=lambda x: \"DONE\" in (x.get(\"content\", \"\") or \"\").upper()\n    )\n\n# Configure the group chat with automatic speaker selection\ngroupchat = GroupChat(\n    agents=[teacher, lesson_planner, lesson_reviewer],\n    speaker_selection_method=\"auto\"  # Uses AutoPattern\n)\n\nmanager = GroupChatManager(\n    name=\"group_manager\",\n    groupchat=groupchat,\n    llm_config=llm_config\n)\n\n# Start with a short initial prompt to keep tokens low\nteacher.initiate_chat(\n    recipient=manager,\n    message=\"Make a simple lesson about the moon.\",\n    max_turns=6,  # Limit total rounds (e.g., 2 per agent max) -  As a safeguard, it's always best to use max_turns to prevent runaway loops.\n    summary_method=\"reflection_with_llm\"\n)"]},{"cell_type":"markdown","id":"98a267fa-8d99-4a63-ae10-a9148a23ebb6","metadata":{},"outputs":[],"source":["## Tools and Extensions<a name=\"tools\"></a>\n","\n","Tools extend agent capabilities beyond text conversations, allowing them to:\n","- Execute code\n","- Access external APIs\n","- Perform calculations\n","- Interact with databases\n","- Generate visualizations\n","\n","Agents gain significant utility through tools as they provide access to external data, APIs, and functionality.  \n","\n","Let's explore how to integrate tools with AG2 agents:\n"]},{"cell_type":"code","id":"269e9a81-2cd0-44c7-8a65-8a62490fa711","metadata":{},"outputs":[],"source":["from autogen import ConversableAgent, register_function, LLMConfig\nfrom typing import Annotated\n\n# Replace with your actual key if running outside this environment\nllm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n\n# Define a simple utility function to check if a number is prime\ndef is_prime(n: Annotated[int, \"Positive integer\"]) -> str:\n    if n < 2:\n        return \"No\"\n    for i in range(2, int(n**0.5) + 1):\n        if n % i == 0:\n            return \"No\"\n    return \"Yes\"\n\n# Create the asking agent and the tool-using agent\nwith llm_config:\n    math_asker = ConversableAgent(\n        name=\"math_asker\",\n        system_message=\"Ask whether a number is prime.\"\n    )\n    math_checker = ConversableAgent(\n        name=\"math_checker\",\n        human_input_mode=\"NEVER\"\n    )\n\n# Register the function between the two agents\nregister_function(\n    is_prime,\n    caller=math_asker,\n    executor=math_checker,\n    description=\"Check if a number is prime. Returns Yes or No.\"\n)\n\n# Start a brief conversation\nmath_checker.initiate_chat(\n    recipient=math_asker,\n    message=\"Is 72 a prime number?\",\n    max_turns=2\n)\n"]},{"cell_type":"markdown","id":"80b21942-44d9-4ea9-8849-0cd31b3891df","metadata":{},"outputs":[],"source":["### What is `register_function(...)` ?\n","\n","In AG2, `register_function(...)` is used to expose a Python function as a **tool** that can be executed by one agent on behalf of another. This enables agents to delegate tasks like computation, data processing, or external API calls.\n","\n","#### Purpose\n","- Extend agent capabilities beyond text generation.\n","- Allow agents to solve tasks through **function execution**.\n","- Enable collaborative workflows between a **caller** and an **executor** agent.\n","\n","#### Parameters\n","- **function**: A regular Python function to be used as a tool.\n","- **caller**: The agent that will request the tool to be used.\n","- **executor**: The agent that will actually execute the function.\n","- **description** *(optional)*: A natural language description of the function for the LLM to decide when to use it.\n","\n","#### Example\n","```python\n","register_function(\n","    is_prime,\n","    caller=math_asker,\n","    executor=math_checker,\n","    description=\"Check if a number is prime. Returns Yes or No.\"\n",")\n"]},{"cell_type":"markdown","id":"5e9259d4-e270-4ac5-be8b-0fad6046b67b","metadata":{},"outputs":[],"source":["## Structured Outputs<a name=\"structured-outputs\"></a>\n","\n","Structured outputs ensure consistent, validated agent responses using Pydantic models.   \n","\n","This is crucial for:\n","  \n","- **Data validation**: Ensuring response format consistency\n","- **API integration**: Reliable data exchange\n","- **Quality assurance**: Preventing malformed outputs\n","- **Type safety**: Clear data contracts\n","\n","**Analogy:** Like standardized hospital forms ensure doctors always record patient info the same way, structured outputs make sure agents respond in predictable, machine-readable formats.\n","\n","\n","In AG2, structured outputs are implemented using Pydantic models and the `response_format` parameter in the `LLMConfig`.\n","\n","To ensure that your agent always returns outputs in a consistent structure, you define a Pydantic class (for example, `ResponseModel`) and assign it to the `response_format` argument of your configuration.\n","\n","This tells the underlying LLM to return a JSON-compatible response matching the defined schema.\n","\n","```python\n","class ResponseModel(BaseModel):\n","    name: str\n","    status: str\n","\n","llm_config = LLMConfig(\n","    api_type=\"openai\",\n","    model=\"gpt-4o-mini\",\n","    response_format=ResponseModel\n",")\n","```\n","\n","With this setup:\n","\n","- The agent automatically formats its responses to match the ResponseModel. \n","- You don‚Äôt need to prompt the LLM to format its response.\n","- The response is parsed and validated by AG2.\n","\n","This approach is essential for reliable automation, integrations, and downstream processing.\n","\n","Let's implement structured outputs with AG2:\n"]},{"cell_type":"code","id":"710be49c-3655-42fc-bdb7-b7a497809d05","metadata":{},"outputs":[],"source":["from pydantic import BaseModel\nfrom autogen import ConversableAgent, LLMConfig\n\n# Define the structure of the agent's output\nclass TicketSummary(BaseModel):\n    customer_name: str\n    issue_type: str\n    urgency_level: str\n    recommended_action: str\n\n# Configure the LLM with the structured output format\nllm_config = LLMConfig(\n    api_type=\"openai\",\n    model=\"gpt-4o-mini\",\n    response_format=TicketSummary,\n)\n\n# Create the agent\nwith llm_config:\n    support_agent = ConversableAgent(\n        name=\"support_agent\",\n        system_message=(\n            \"You are a support assistant. Summarize a customer ticket using:\"\n            \"\\n- customer_name\"\n            \"\\n- issue_type (e.g. login issue, billing problem, bug report)\"\n            \"\\n- urgency_level (Low, Medium, High)\"\n            \"\\n- recommended_action\"\n        ),\n    )\n\n# Start a structured conversation\nsupport_agent.initiate_chat(\n    recipient=support_agent,\n    message=\"Ticket: John Doe is unable to reset his password and has an important meeting in 30 minutes.\",\n    max_turns=1\n)\n"]},{"cell_type":"markdown","id":"e3636922-fd7e-4dc8-9229-f4d22838965e","metadata":{},"outputs":[],"source":["## Best Practices<a name=\"best-practices\"></a>\n","\n","Based on our exploration of AG2 concepts, here are key best practices for building robust agent systems:\n","\n","### Configuration and security\n","- **Never hardcode API keys** - use environment variables\n","- **Use config lists** for production systems with fallback models\n","- **Set appropriate temperature** values (0.0 for deterministic, 0.7-1.0 for creative)\n","- **Implement rate limiting** and error handling\n","\n","### Agent design\n","- **Write clear system messages** that define role, capabilities, and constraints\n","- **Set max_consecutive_auto_reply** to prevent infinite loops\n","- **Choose appropriate human_input_mode** based on use case\n","- **Specialize agents** for specific tasks rather than creating generalists\n","\n","### HITL implementation\n","- **Use HITL for high-stakes decisions** requiring human judgment\n","- **Implement clear escalation criteria** (amount thresholds, risk levels)\n","- **Provide context** to human supervisors for informed decisions\n","- **Log all human interventions** for audit trails\n","\n","### Multi-agent orchestration\n","- **Design clear workflows** with defined handoffs between agents\n","- **Use GroupChat** for collaborative problem-solving\n","- **Implement termination conditions** to prevent endless conversations\n","- **Monitor conversation quality** and intervention points\n","\n","### Tools and integration\n","- **Create focused tools** for specific capabilities\n","- **Implement proper error handling** in tool functions\n","- **Validate tool inputs** and outputs\n","- **Document tool capabilities** clearly for agents\n","\n","### Structured outputs\n","- **Use Pydantic models** for data validation\n","- **Define clear schemas** for consistent outputs\n","- **Implement proper validation** with meaningful error messages\n","- **Version your schemas** for backward compatibility\n"]},{"cell_type":"markdown","id":"21cee35b-be6d-422e-a2d6-6f302798cff8","metadata":{},"outputs":[],"source":["## Conclusion<a name=\"conclusion\"></a>\n","\n","Congratulations! You've completed a comprehensive tour of AG2's basic concepts. Let's recap what we've learned:\n","\n","### Key concepts mastered:\n","\n","- **LLM Configuration** - The foundation that connects agents to language models\n","- **ConversableAgent** - The core building block for all AG2 agents\n","- **Human in the Loop (HITL)** - Enabling human oversight in AI workflows\n","- **Agent Orchestration** - Coordinating multiple agents for complex tasks\n","- **Tools & Extensions** - Extending agent capabilities beyond text\n","- **Structured Outputs** - Ensuring consistent, validated responses\n","\n","### Practical skills developed:\n","\n","- Creating and configuring specialized agents\n","- Implementing multi-agent collaboration patterns\n","- Building HITL workflows for critical decisions\n","- Integrating tools and external capabilities\n","- Validating outputs with structured schemas\n","- Following security and operational best practices\n","\n","### Next steps:\n","\n","Now that you understand AG2's basic concepts, you can:\n","\n","1. **Build Domain-Specific Applications** - Apply these concepts to your specific use case.\n","2. **Explore Advanced Features** - Dive into code execution, web scraping, and API integrations.\n","3. **Scale Your Systems** - Learn about production deployment and monitoring.\n","4. **Join the Community** - Contribute to the AG2 ecosystem and learn from others.\n","\n","### Things to remember:\n","\n","- **Start simple** and gradually add complexity.\n","- **Test thoroughly** with various scenarios.\n","- **Monitor performance** and adjust configurations.\n","- **Follow best practices** for security and reliability.\n","- **Keep learning** as AG2 continues to evolve.\n","\n","AG2 provides a powerful foundation for building intelligent, collaborative AI systems. The concepts you've learned here will serve as building blocks for more advanced implementations.  \n","\n","### Advanced agentic design patterns:  \n","  \n","AG2 supports advanced features like custom rules for conversation endings, RAG, code execution, and secure tool use. You can learn more from the official documentation.  \n","  \n","Happy building with AG2! ü§ñ‚ú®\n"]},{"cell_type":"markdown","id":"5911f242-b8b9-4ae4-bb86-daa52e209712","metadata":{},"outputs":[],"source":["## Authors\n"]},{"cell_type":"markdown","id":"9d331c5c-bf8c-4aac-8b3e-0ccb9ca297bd","metadata":{},"outputs":[],"source":["[Faranak Heidari](https://www.linkedin.com/in/faranakhdr/) is a Data Scientist and AI developr at IBM with expertise in GenAI, machine learning, and data analytics. Experienced in building LLMs, forecasting models, and scalable ML pipelines for domains like healthcare. Passionate about driving innovation and collaborating with teams to integrate AI into real-world workflows.\n","\n","[Joshua Zhou](https://www.linkedin.com/in/joshuazhou1/) is a Data Scientist Intern at IBM.\n"]},{"cell_type":"markdown","id":"68170bb8-791d-4655-9cb9-661edfb4756d","metadata":{},"outputs":[],"source":["## Change Log\n","\n","<details>\n","    <summary>Click here for the changelog</summary>\n","\n","|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2025-07-17|0.1|Faranak Heidari|Initial version created|\n","|2025-07-27|0.2|Steve Ryan|ID review and format fixes|\n","|2025-07-28|0.3|Mercedes Schneider|QA pass with edits|\n","</details>\n","\n","---\n","\n","\n","Copyright ¬© IBM Corporation. All rights reserved.\n"]},{"cell_type":"code","id":"0f77cd34-9512-47d4-8e29-3d750f6db33e","metadata":{},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.8"},"prev_pub_hash":"17556ac98af6ba46cf3370eae526d0c678ae2e3c89216563a6c4eaec56777c60"},"nbformat":4,"nbformat_minor":4}