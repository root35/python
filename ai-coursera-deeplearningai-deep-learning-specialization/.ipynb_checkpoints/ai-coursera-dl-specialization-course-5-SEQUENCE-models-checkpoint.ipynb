{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEQUENCE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background:#DDEEEE;padding: 15px;\">Recurrent Networks</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variants: LSTM, GRU, bi-directional RNN, etc.\n",
    "  \n",
    "  \n",
    "- **Sequence data**:\n",
    "  - input `x` -> output `x`\n",
    "  - not always the same length\n",
    "  - not always both sequence data\n",
    "  - training examples of varying lengths\n",
    "  - features for the same input element learned accross different positions in text\n",
    "    - ex: 'Hermione' in 1st position is a sign that can be a person's name\n",
    "    - this info cannot be used when 'Hermione' is in a different position\n",
    "  \n",
    "<img src=\"images/rnns-sequence-data-examples.png\" width=\"550\">\n",
    "\n",
    "#### Vocabulary\n",
    "\n",
    "#### One-hot encoding\n",
    "- Vector with one value and all the rest is zeros\n",
    "- If vocab size is 10.000: each word in a sentence is a 10.000 length vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Notation*\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-01-notation-1.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-01-notation-2.png\" width=\"950\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Basic architecture*\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-02-architecture-1.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-02-architecture-2.png\" width=\"950\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Forward propagation formulas*\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-03-forward-propagation-formulas-1.png\" width=\"950\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Forward propagation architecture*\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-04-forward-propagation-architecture-1.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-04-forward-propagation-architecture-2.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-04-forward-propagation-architecture-3.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-04-forward-propagation-architecture-4.png\" width=\"950\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Simplified forward propagation formula*\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-05-forward-propagation-formulas-simplified.png\" width=\"950\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Forward propagation -> Loss -> Backpropagation*\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-06-forward-propagation-1.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-06-forward-propagation-2.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-06-forward-propagation-3.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-06-forward-propagation-4.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-06-forward-propagation-5.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-07-loss-function-1.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-07-loss-function-2.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-08-backpropagation-1.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-08-backpropagation-2.png\" width=\"950\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Types of RNNs*\n",
    "\n",
    "\n",
    "<table align=center style=\"border:1px solid black\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:left; width: 150px;\">Many to many</th>\n",
    "        <td style=\"text-align:left; width: 280px;\">\n",
    "            • input = sequence<br/>• output = sequence\n",
    "            <br/>• type 1: same length<br/>• type 2: different length\n",
    "        </td>\n",
    "        <td style=\"text-align:left; width: 300px;\">\n",
    "            .\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align:left; width: 150px;\">.</th>\n",
    "        <td style=\"text-align:left; width: 280px;\">\n",
    "            • type 2: different length\n",
    "            <br/>• encoder: reads source sentence\n",
    "            <br/>• decoder: outputs target sentence\n",
    "        </td>\n",
    "        <td style=\"text-align:left; width: 300px;\">\n",
    "            machine translation, x = source, y = target\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align:left; width: 150px;\">Many to one</th>\n",
    "        <td style=\"text-align:left; width: 280px;\">\n",
    "            • input = sequence<br/>• output = y_hat only at last time step\n",
    "        </td>\n",
    "        <td style=\"text-align:left; width: 300px;\">\n",
    "            sentiment classification, x = text, y = star | no star\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align:left; width: 150px;\">One to one</th>\n",
    "        <td style=\"text-align:left; width: 280px;\">\n",
    "            • input = one value<br/>• output = one value<br/>• same as standard nn, not interesting\n",
    "        </td>\n",
    "        <td style=\"text-align:left; width: 300px;\">\n",
    "             .\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style=\"text-align:left; width: 150px;\">One to many</th>\n",
    "        <td style=\"text-align:left; width: 280px;\">\n",
    "            • input = empty<br/>• output = sequence\n",
    "            <br/>• reading input only at first time step\n",
    "            <br/>• x input of next time steps is synthesized output from previous time step\n",
    "        </td>\n",
    "        <td style=\"text-align:left; width: 300px;\">\n",
    "            music generation, x = none, y = sequence of notes\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br/>\n",
    "<img src=\"images/rnns-types.jpg\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Language Modelling with RNNs*\n",
    "\n",
    "- **Role**: given a sentence, tells you what's the probability of an interpretation of that sentence\n",
    "- Fundamental component for Speech Recognition and MT\n",
    "  - MT wants to output only sentences that are likely\n",
    "    \n",
    "    \n",
    "- **Example**:\n",
    "  - Speech Recognition: P(The apple and pair salad) VS P(The apple and pear salad)\n",
    "  - Given a text, what is the probability that the next sentence would be a given sentence?\n",
    "   \n",
    "   \n",
    "- **Input**: a sequence of words\n",
    "- **Output**: probability of the input sequence of words\n",
    "  \n",
    "  \n",
    "- **Training set**: large corpus of english text\n",
    "- **Step 1**: tokenization -> vocabulary = index of one-hot vectors\n",
    "  - `<eos>` very important, helps system learn what a sentence is\n",
    "  - `<unk>` words not in the vocab from training  \n",
    "- **Step 2**: build an RNN to model the chances of each sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sequence-models_rnns/rnn-09-language-modelling-1.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-09-language-modelling-2.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-09-language-modelling-3.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-09-language-modelling-4.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-09-language-modelling-5.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-09-language-modelling-6.png\" width=\"950\">\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-09-language-modelling-7.png\" width=\"950\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Vanishing Gradients with RNNs*\n",
    "\n",
    "- Gradients from last layer would have a very hard time propagating back to first layers   \n",
    "  -> Not very good for catching very long range dependencies\n",
    "- Each step is merely influenced by the local time steps, the ones that are very close\n",
    "- Very difficult for output to be influenced by very early intputs,    \n",
    "  because difficult for network to backpropagate error from the end to very early time steps   \n",
    "= One of the weaknesses of basic RNNs   \n",
    "= Can cause vanishing or exploding gradients\n",
    "   \n",
    "   \n",
    "### **Exploding gradient -> Gradient clipping**\n",
    "  - `NaN`, easy to spot, easier to solve that vanishing gradient\n",
    "  - robust solution: gradient clipping    \n",
    "    = rescaling the vector of gradients to a certain range so that it doesn't surpass a certain max value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Gated Recurrent Unit (GRU)*\n",
    "\n",
    "  - GRU more recent than LSTM\n",
    "  - Simpler so easier to scale to very big networks\n",
    "  - Each is used for different problems\n",
    "  - **reset gate**: decides how much past info should be forgotten\n",
    "  \n",
    "  \n",
    "https://www.pluralsight.com/guides/lstm-versus-gru-units-in-rnn\n",
    "   \n",
    "   \n",
    "<img src=\"images/sequence-models_rnns/rnn-10-gru-1.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-10-gru-2.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-10-gru-3.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-10-gru-4.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-10-gru-5.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-10-gru-6.png\" width=\"950\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Long-Short Term Memory (LSTM)*\n",
    "\n",
    "- A long short-term memory (LSTM) network is a type of RNN model that avoids the vanishing gradient problem by adding 'forget' gates\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-11-lstm-1.png\" width=\"950\">\n",
    "\n",
    "- **Forget** and **Update** gates make LSTM and even GRU good at memorizing **very long range** dependencies for many time steps\n",
    "- Variant: **peephole connection** = sometimes we add `C<t-1>` in the gates computation (entre crochets)    \n",
    "  = output depends also on previous value\n",
    "  - gates = N-dim vectors for ex (N = nb units), `C<t-1>` also N-dim vector\n",
    "  - 5th element of `C<t-1>` only affects the 5th element of the gates vectors\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-11-lstm-2.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-11-lstm-3.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-11-lstm-4.png\" width=\"950\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Bi-directional RNNs*\n",
    "\n",
    "- **Disadvantage**: you need the entire sequence of data before you can make a prediction\n",
    "  - ex: speech recognition, you need to wait until the person finishes her sentence before you can start speech recognition prediction\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-12-bi-rnn-1.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-12-bi-rnn-2.png\" width=\"950\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Deep RNNs*\n",
    "\n",
    "<img src=\"images/sequence-models_rnns/rnn-13-deep-rnn-1.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-13-deep-rnn-2.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-13-deep-rnn-3.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-13-deep-rnn-4.png\" width=\"950\">\n",
    "<img src=\"images/sequence-models_rnns/rnn-13-deep-rnn-5.png\" width=\"950\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *C5 W1 - Sequence models - Assignment 1: Building an RNN step by step*\n",
    "\n",
    "$x^{2}$ superscript\n",
    "$x_{2}$ subscript\n",
    "\n",
    "<table align=left style=\"border:1px solid black\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left; width: 100px;\">$-^{[l]}$</td>\n",
    "        <td style=\"text-align:left; width: 150px;\">layer</td>\n",
    "        <td style=\"text-align:center; width: 100px;\" rowspan=4>\n",
    "            $a^{(2)[3]<4>}_{i}$ \n",
    "        </td>\n",
    "        <td style=\"text-align:left; width: 200px;\" rowspan=4>\n",
    "            denotes the activation of the:\n",
    "            <br/>- 2nd training example\n",
    "            <br/>- 3rd layer\n",
    "            <br/>- 4th time step\n",
    "            <br/>- 5th entry in the vector\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$-^{(i)}$</td>\n",
    "        <td style=\"text-align:left;\">example</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$-^{<t>}$</td>\n",
    "        <td style=\"text-align:left;\">time-step</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$-_{i}$</td>\n",
    "        <td style=\"text-align:left;\">vector entry</td>\n",
    "    </tr>\n",
    "</table>\n",
    "  \n",
    "  \n",
    "<br/>\n",
    "  \n",
    "  \n",
    "<table align=left style=\"border:1px solid black\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:left; width: 100px;\">Notation</th>\n",
    "        <th style=\"text-align:left; width: 350px;\">Content</th>\n",
    "        <th style=\"text-align:left; width: 400px;\">Shape</th>\n",
    "        <th style=\"text-align:left; width: 100px;\">Variable name</th>\n",
    "    </tr>\n",
    "    <!---><--->\n",
    "    <tbody>\n",
    "    <tr style=\"background-color: #DFF2FF;\">\n",
    "        <th style=\"text-align:left;\" colspan=4>Input $x$</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$x$</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            Input fed into the RNN\n",
    "            <br/>\n",
    "            = all training examples or one mini-batch\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            3-dimensional tensor\n",
    "            <br/>($n_{x}$, $m$, $T_{x}$)\n",
    "            <br/>(nb_units, mini_batch_size, nb_time_steps)\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$x^{<t>}$</td>\n",
    "        <td style=\"text-align:left;\">Input used at time-step $t$</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            2-dimensional tensor\n",
    "            <br/>($n_{x}$, $m$)\n",
    "            <br/>(nb_units, mini_batch_size)\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\"><code>xt</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$m$</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            number of training examples\n",
    "            <br/>or mini-batches size</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            Tensor shape = (vocab-size, mini_batch_size, $T_{x}$)\n",
    "            <br/>ex: (5000, 20, 10)\n",
    "            <br/>vectorization: we stack 20 columns (20 $x_{i}$ examples)\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$T_{x}$</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            Number of time-steps in a single training example $x^{(i)}$\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$x^{(i)<t>}$</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            $t^{th}$ time-step of $i^{th}$ input example\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            (5000,)<br/>vocab size = 5000\n",
    "            <br/>one-dimensional input vector\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$n_{x}$</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            Number of units in a single time-step of a single training example\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "    </tr>\n",
    "    </tbody>\n",
    "    <!---><--->\n",
    "    <tbody>\n",
    "    <tr style=\"background-color: #DFF2FF;\">\n",
    "        <th style=\"text-align:left;\" colspan=4>Hidden state $a$</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$a^{<t>}$</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            A \"hidden state\": \n",
    "            <br/>the activation passed to the RNN from one time step to another\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            ($n_{a}$, $m$)\n",
    "            <br/>for a mini-batch of $m$ training examples\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            <code>a_prev</code> or <code>a_next</code>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            ($n_{a}$, $m$, $T_{x}$)\n",
    "            <br/>for a given time step $t$\n",
    "            <br/><br/>\n",
    "            -> We loop through the time steps with index $t$, and work with the $a^{<t>}$ 2D slice of this 3D tensor\n",
    "            <br/><br/>\n",
    "            length $n_{a}$\n",
    "            <br/>for a single training example\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "    </tr>\n",
    "    </tbody>\n",
    "    <!---><--->\n",
    "    <tbody>\n",
    "    <tr style=\"background-color: #DFF2FF;\">\n",
    "        <th style=\"text-align:left;\" colspan=4>Prediction $\\hat{y}$</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$\\hat{y}$</td>\n",
    "        <td style=\"text-align:left;\">A prediction</td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            ($n_{y}$, $m$, $T_{y}$)\n",
    "            <br/><br/>\n",
    "            • $n_{y}$: nb of units in the vector representing the prediciton\n",
    "            <br/>• $m$: number of examples in a mini-batch\n",
    "            <br/>• $T_{y}$: number of time steps in the prediction\n",
    "        </td>\n",
    "        <td style=\"text-align:left;\"><code>y_pred</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">$\\hat{y}^{\\langle t \\rangle}$</td>\n",
    "        <td style=\"text-align:left;\">Prediction for a single time step $t$</td>\n",
    "        <td style=\"text-align:left;\">($n_{y}$, $m$)</td>\n",
    "        <td style=\"text-align:left;\"><code>yt_pred</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "        <td style=\"text-align:left;\">     </td>\n",
    "    </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "<br/>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUMPY SLICING !!!!!!!!!!!\n",
    "https://www.pythoninformer.com/python-libraries/numpy/index-and-slice/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background:#DDEEEE;padding: 15px;\">Word embeddings</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Word embeddings*\n",
    "\n",
    "- Featurized representation:\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-01.png\" width=\"700\">\n",
    "  \n",
    "  \n",
    "- Words similarity\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-02.png\" width=\"700\">  \n",
    "  \n",
    "  \n",
    "- Visualizing embeddings with t-SNE algorithm\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-03.png\" width=\"700\">\n",
    "  \n",
    "  \n",
    "- Transfer learning\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-04.png\" width=\"700\">\n",
    "   \n",
    "   \n",
    "- Using embeddings: analogy reasoning\n",
    "  - $e_{man}$ - $e_{woman}$ = [-2, 0, 0, 0] -> because main difference between them is the Gender feature\n",
    "  - $e_{king}$ - $e_{queen}$ = [-2, 0, 0, 0] -> idem\n",
    "  - First pointed out by Mikolov et al. 2013: \"Linguistic regularities in continuous space word representations\"\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-05.png\" width=\"700\">\n",
    "\n",
    "  \n",
    "  - The vector difference between 'man' and 'woman' is very similar to the vector difference between 'queen' and 'king'\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-06.png\" width=\"700\">\n",
    "  \n",
    "  \n",
    "  - Cosine similarity: most commonly used (cosine of the angle between the 2 vectors)\n",
    "    - normalizes to the lengths of the 2 vectors\n",
    "  - Squared distance: measures dissimilarity => similarity = -squared_dist\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-07.png\" width=\"700\">\n",
    "\n",
    "\n",
    "- Embedding matrix (vs one-hot encodings):\n",
    "  - multiplying the embedding matrix $E$ with the one-hot vector $O_{orange}$ for example, ends-up selecting the column in the matrix corresponding to the word 'orange':   \n",
    "  $E$ * $O_{j}$ = $e_{j}$  -> embedding for word $j$\n",
    "<img src=\"images/sequence-models_word-embeddings/embeddings-08.png\" width=\"700\">\n",
    "\n",
    "- Learning an embedding:\n",
    "  - intialize the embedding matrix $E$ with zeros,\n",
    "  - then use gradient descent to learn all the parameters of this matrix\n",
    "  - and $E$ * $O_{j}$ gives you the embedding for a given word $j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Learning word embeddings*\n",
    "\n",
    "#### Word2Vec\n",
    "\n",
    "\n",
    "#### Negative Sampling\n",
    "\n",
    "\n",
    "#### GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Applications of word embeddings*\n",
    "\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background:#DDEEEE;padding: 15px;\">Attention mechanisms</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "\n",
    "- Technique de réduction de dimension qui projette les données sur k dimensions en maximisant la variance des données de la manière suivante :\n",
    "- Étape 1: Normaliser les données pour avoir une moyenne de 0 et un écart-type de 1\n",
    "\n",
    "https://stanford.edu/~shervine/l/fr/teaching/cs-221/pense-bete-modeles-reflex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
