{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OPTIMIZING NEURAL NETWORKS\n",
    "\n",
    "**!!! READ**: [deeplearning.ai: Initialization + Optimization](https://www.deeplearning.ai/ai-notes/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatch train/test distribution\n",
    " - training = cat picture from web pages               -> high res\n",
    " - test set = cat pictures from users using your app   -> blurry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Bias/Variance tradeoff*\n",
    " (Optimal/human error = 0% - always compare to optimal error)   \n",
    " Training error: Tells you how much fitting is done, and if you have a bias problem  \n",
    " How much higher is error on dev set compared to training set tells you how bas is the variance problem    \n",
    " In the past, reducing bias always led to more variance, and reducing variance always let to more bias, so we had to choose   \n",
    " Now we have the tools to drive down one without hurting the other much       \n",
    "  \n",
    " - **high variance** = too much flexibility\n",
    "   - train set error 1%\n",
    "   - dev set error 11%   \n",
    " -> doing well on train set but poorly on dev set, not generalizing well, curve with too much flexibility\n",
    " - SOLUTION: get more data, regularization, change network architecture      \n",
    "    \n",
    "      \n",
    " - **high bias** = underfitting   \n",
    "   - train set error 15%\n",
    "   - dev set error 16%   \n",
    " -> not fitting the training set   \n",
    " - SOLUTION: bigger network, train longer, change network architecture  \n",
    "    \n",
    "      \n",
    " - **high bias + high variance** \n",
    "   - train set error 15%\n",
    "   - dev set error 30%   \n",
    " -> worst case scenario\n",
    "    \n",
    "      \n",
    " - **low bias + low variance** \n",
    "   - train set error 0.5%\n",
    "   - dev set error 1%   \n",
    " -> best case scenario. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal (Bayes) error:\n",
    "base assumption on human error. 0%   \n",
    "can change when even human can't judge (blurry images).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background:#DDEEEE;padding: 15px;\">Standardization</h1>\n",
    "\n",
    "- substract the mean of the whole numpy array from each example,     \n",
    "- and then divide each example by the standard deviation of the whole numpy array  \n",
    "- ex: `train_set_x = train_set_x_flatten/255`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background:#DDEEEE;padding: 15px;\">Regularization</h1>\n",
    "   \n",
    "   \n",
    "(course 2 week 1)\n",
    "\n",
    "- **Why it reduces overfitting**:   \n",
    "  - prevents weight matrices from being too large\n",
    "  - if `lambda` very big   \n",
    "  => `W` very small & zero out the impact of lots of hidden neurons    \n",
    "  => `z` very small   \n",
    "  - and nn becomes ***smaller and simpler***\n",
    "  - takes you closer to underfitting\n",
    "  - when `z` small, function is linear (see picture curve), only becomes less linear with larger values of z\n",
    "    \n",
    "     \n",
    "- **First** focus on finding a good algorithm, **then** correct overfitting\n",
    "- `W` is usually very high dimension, while `b` is just a scalar, so don't bother regularizing `b`\n",
    "- **lambd**: the regularization parameter, is set using the dev set    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **L2** regularization -> more often used, also called ***weight decay***   \n",
    "= multiplying the weight matrix by numbers sligthly less than 1.  \n",
    "cours 2 week 1 exo 2: \n",
    "  - L2 regularization makes your decision boundary smoother. If  Î»  is too large, it is also possible to \"oversmooth\", resulting in a model with high bias   \n",
    "  - L2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights. Thus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It becomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes more slowly as the input changes\n",
    "  - Weights end up smaller (\"weight decay\"): Weights are pushed to smaller values   \n",
    "  \n",
    "  \n",
    "- **L1** regularization -> W becomes sparse \n",
    "- **Data augmentation**      \n",
    "- **Dropout** regularization\n",
    "- **Weight regularization**: LASSO, Ridge, ElasticNet\n",
    "- **Early stopping**: stops the training process as soon as the validation loss reaches a plateau or starts to increase\n",
    "  - **orthogonalization**\n",
    "  -> good alternative = use L2 and train for as long as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Dropout regularization*\n",
    "\n",
    "- Each training example is trained on a different smaller network:\n",
    "  - different units dropped for each training example\n",
    "  - and for each training example, different units dropped at each iteration\n",
    "- forces the model to avoid relying too much on particular sets of features\n",
    "- Prevents from putting too much weight on some features: inputs can be randomly eliminated, so training can't rely on any one feature, so has to spead out weights   \n",
    "  -> **no overfitting**   \n",
    "  \n",
    "<img src=\"images/regularization-dropout.png\" width=\"650\">\n",
    "   \n",
    "    \n",
    "- **Method**:\n",
    "  - for each training example\n",
    "    - go through each layer of the nn\n",
    "      - for each node in a layer, compute the probability that it can be dropped out (random)\n",
    "      - then remove all those nodes   \n",
    "      -> much smaller nn\n",
    "    - then do backpropagation = training this one example with the smaller network\n",
    "  - for next training example, do the same:\n",
    "    - compute probas -> drop nodes -> backpropagation -> training   \n",
    "  \n",
    "  \n",
    "- **Implementation**:\n",
    "  - ***inverted dropout*** technique (cf. screenshots) -> by for most used today\n",
    "  - `keep_prob = 0.2` -> reduce layers by 20%   \n",
    "  - can be set differently for each layer, or not applied to some layers:\n",
    "    - big layers -> big weight matrices -> higher keep_prob\n",
    "    - layers with more risk of overfitting -> lower keep_prob     \n",
    "   \n",
    "   \n",
    "\n",
    "- Better to deactivate it during **optimization**, when plotting cost function (keep_prob=1) (cf. explanation: Course 2 Week 1 Understanding Dropout)     \n",
    "  - **First** focus on finding a good algorithm, **then** correct overfitting\n",
    "- Do not use at **test time**: you don't want your output to be random\n",
    "  - if you want to do it: run prediction process many times with different units dropped randomly at each time and average accross them   \n",
    "  -> computationally inefficient and gives roughly the same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Weight regularization*\n",
    "\n",
    "<img src=\"images/regularization-weight-regularization.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Early stopping*\n",
    "\n",
    "<img src=\"images/regularization-early-stopping.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background:#DDEEEE;padding: 15px;\">Optimization</h1>\n",
    "  \n",
    "  \n",
    "(course 2 week 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Normalization*\n",
    "\n",
    "- **speed up training**. \n",
    "  - same variance for all features (all features on similar small scales)   \n",
    "  -> cost function more symmetric   \n",
    "  -> faster and easier to optimize\n",
    "- divide each row or `x` by its norm `ð‘¥ / â€–ð‘¥â€–`  \n",
    "- increases performance because **gradient descent converges faster**  \n",
    "- https://stats.stackexchange.com/questions/211436/why-normalize-images-by-subtracting-datasets-image-mean-instead-of-the-current    \n",
    "   \n",
    "   \n",
    "- 2 steps:\n",
    "  1. subtract the mean (mu)\n",
    "  2. normalize variances (sigma_^)   \n",
    "- **cf screenshot** course 2 week 1 Normalizing inputs: variance of x1 and x2 both equal to 1\n",
    "- use same values to normalize test set (mu and sigma_^)   \n",
    "-> all data must go throught the same transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Vanishing/Exploding gradients*\n",
    "\n",
    "- **Exploding**: activation values ***grows*** exponentially as a function of the number of layers\n",
    "- **Vanishing**: activation values ***decreases*** exponentially as a function of the number of layers  \n",
    "  \n",
    "  \n",
    "-> GD tiny little steps -> training very long   \n",
    "was for a long time a barrier for training deep learning\n",
    "  \n",
    "   \n",
    "- **SOLUTION** (partial): better choice of random initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Weight initialization*\n",
    "\n",
    "- prevents vanishing/exploding gradients\n",
    "   \n",
    "   \n",
    "\n",
    "- Set the variance of `W[l]` to be equal to `1/n`, or `2/n` with ReLU   \n",
    "  -> all input features are mean 0 and variance 1  \n",
    "  -> weights not too much bigger than 1 and not too much less than 1   \n",
    "  -> `Z` on the same scale   \n",
    "  -> doesn't completely solve the problem but helps prevent it    \n",
    "  \n",
    "  \n",
    "- To do that, we initialize the weights:   \n",
    "     `W[l] = np.random.randn(shape) * np.sqrt(1 / n[l-1])`    \n",
    "      \n",
    "    `n[l-1]` number of neurons in the previous layers, number of neurons being fed in each unit of current layer   \n",
    "    \n",
    "    \n",
    "- Variants:\n",
    "  - with ReLU: `np.sqrt(2 / n[l-1])`\n",
    "  - with tanh: `np.sqrt(2 / n[l-1])` = Xavier initialization\n",
    "  - `np.sqrt(2 / (n[l-1] + n[l]))`\n",
    "  \n",
    "  \n",
    "- **Cours 2 Week 1 Exo 1**: He et al., 2015. (If you have heard of \"Xavier initialization\", this is similar except Xavier initialization uses a scaling factor for the weights  W[l]W[l]  of sqrt(1./layers_dims[l-1]) where He initialization would use sqrt(2./layers_dims[l-1]).)\n",
    "\n",
    "### *Xavier initialization*\n",
    "\n",
    "Instead of initializing the weights in a purely random manner, Xavier initialization enables to have initial weights that take into account characteristics that are unique to the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Numerical approximation of gradients*\n",
    "\n",
    "- Compute the slope not just using a point after, but using a point after `Î¸ + Îµ` and a point before `Î¸ - Îµ` with same distance to current point `Î¸`  \n",
    "   \n",
    "   `[f(Î¸ + Îµ) + f(Î¸ - Îµ)] / 2 * Îµ`\n",
    "   \n",
    "  instead of:   \n",
    "\n",
    "   `[f(Î¸ + Îµ) / Îµ`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Gradient Checking*\n",
    "\n",
    "- Used during the backpropagation: compares the value of the *analytical gradient* to the *numerical gradient* at given points and plays the role of a ***sanity-check for correctness***   \n",
    "   \n",
    "   \n",
    "- [Gradient Checking implementation](https://www.coursera.org/learn/deep-neural-network/lecture/6igIc/gradient-checking-implementation-notes)  \n",
    "  - do not use at training, only at debut\n",
    "  - does not work with dropout, so deactivate dropout (`keep_dims = 1.0`)\n",
    "  - analysis...\n",
    "  \n",
    "  \n",
    "- Concatenate all parameters into a giant flat vector:  \n",
    "  `Î¸` = `W[1] b[1] ... W[L] b[L]`   \n",
    "  \n",
    "  \n",
    "- Do the same with derivatives:   \n",
    "  `d_Î¸` = `d_W[1] d_b[1] ... d_W[L] d_b[L]`   \n",
    "  \n",
    "  \n",
    "- **Question**: Is   `d_Î¸` the gradient of the cost function `J(Î¸)`?\n",
    "  \n",
    "  - compute:\n",
    "   \n",
    "    ```\n",
    "    for each i:\n",
    "      d_Î¸_approx[i] = [J(Î¸_1 ... tÎ¸_i + Îµ ...) + J(Î¸_1 ... Î¸_i - Îµ ...)] / (2 * Îµ)\n",
    "    ```   \n",
    "  \n",
    "  - Check if `d_Î¸_approx[i]` is equal to `d_Î¸[i]` (euclidean distance)\n",
    "  - Result should be equal to the value set for `Îµ`\n",
    "  - Otherwise, check visualization of data to find data points for which value is much higher or lower = incorrect derivative computation\n",
    "  \n",
    "<img src=\"images/optimization-gradient-checking.png\" width=\"650\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Optimization algorithms*\n",
    "\n",
    "- Used to train NNs much faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting small batch\n",
    "\n",
    "<img src=\"images/optimization-overfitting-small-batch.png\" width=\"650\" align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch gradient descent\n",
    "[coursera ai: c2 w2 Mini-batch GD](https://www.coursera.org/learn/deep-neural-network/lecture/qcogH/mini-batch-gradient-descent)\n",
    "\n",
    "[coursera ai: c2 w2 Understanding mini-batch GD](https://www.coursera.org/learn/deep-neural-network/lecture/lBXu8/understanding-mini-batch-gradient-descent)\n",
    "\n",
    "- Batch GD = process the entire training set all at the same time = one batch\n",
    "- Mini-batch GD = process mini-batches at the same time:    \n",
    "  forward propagation -> cost function -> backpropagation -> weights update     \n",
    "  = **much faster** because GD larger steps (vectorization)\n",
    "- 5.000.000 training examples, mini-batches of 1.000   \n",
    "  - = 5.000 mini-batches: `[X{1}, X{2}...]`\n",
    "  - mini-batch `t: X{t}, Y{t}` with `X{t}.shape = (Mx, 1000)` and `Y{t}.shape = (Mx, 1)`\n",
    "- mini-batch size: between 2 and m (nb trng ex), not too large or too small    \n",
    "  see coursera 'Understanding mini-batch GD' :\n",
    "  - shuffle training data before splitting into mini-batches\n",
    "  - 64, 128, 256, 512, 1024...\n",
    "  - fits in CPU/GPU memory\n",
    "  - try different values to find the one that makes GD the more efficient  \n",
    "- With a well-turned mini-batch size, usually it outperforms either gradient descent or stochastic gradient descent (particularly when the training set is large)\n",
    "- Shuffling and Partitioning are the two steps required to build mini-batches\n",
    "- Powers of two are often chosen to be the mini-batch size, e.g., 16, 32, 64, 128.\n",
    "  \n",
    "  \n",
    "- **Stochastic gradient descent**: \n",
    "  - Each training example is its own mini-batch, i.e. mini-batch size = 1    \n",
    "  - You use only 1 training example before updating the gradients\n",
    "  - When the training set is large, SGD can be faster. But the parameters will \"oscillate\" toward the minimum rather than converge smoothly  \n",
    "   \n",
    "   \n",
    "- **Batch GD**:mini-batch size = m (nb trng ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially Weighted (Moving) Averages\n",
    "\n",
    "- Faster than mini-batch GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Momentum\n",
    " - Faster than standard GD\n",
    " - Speeds up GD when oscillations high vertically and small horizontally\n",
    " - Oscillating steps: ***smaller vertically and larger horizontally***   \n",
    "   = slows down learning in vertical direction + speeds it up in horizontal direction   \n",
    "   -> faster!\n",
    " - See **implementation details** in the course\n",
    "    \n",
    "     \n",
    " - **Momentum** takes into account the **past gradients** to smooth out the update. We will store the 'direction' of the previous gradients in the variable  `v` . Formally, this will be the ***exponentially weighted average of the gradient on previous steps***. You can also think of  `v`  as the **velocity** of a ball rolling downhill, building up **speed (and momentum)** according to the direction of the gradient/slope of the hill.\n",
    "  \n",
    "  \n",
    "- The velocity is initialized with zeros. So the algorithm will take a few iterations to \"build up\" velocity and start to take bigger steps.\n",
    "- If  Î²=0Î²=0 , then this just becomes standard gradient descent without momentum\n",
    "  \n",
    "  \n",
    "- **How do you choose `Î²`:**\n",
    "  - The larger the momentum `Î²` is, the smoother the update because the more we take the past gradients into account. But if `Î²` is too big, it could also smooth out the updates too much.\n",
    "  - Common values for `Î²` range from `0.8` to `0.999`. If you don't feel inclined to tune this, `Î²=0.9`  is often a reasonable default.\n",
    "  - Tuning the optimal `Î²` for your model might need trying several values to see what works best in term of reducing the value of the cost function `J`.\n",
    "  \n",
    "  \n",
    "- Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent.\n",
    "- You have to tune a momentum hyperparameter  Î²Î²  and a learning rate  Î±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "\n",
    " - Speeds up GD when oscillations high vertically and small horizontally\n",
    " - Oscillating steps: ***smaller vertically and larger horizontally***   \n",
    "   = slows down learning in vertical direction + speeds it up in horizontal direction   \n",
    "   -> faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization: Adaptive Momentum Estimation\n",
    "course 2 week 2\n",
    "\n",
    "- **Combination of Momentum and RMSProp**:\n",
    "  - Compute `dW`, `db` using current mini-batch\n",
    "  - Compute Momentum: `V_dW` and `V_db` (parameter `beta1`)\n",
    "  - Compute RMSProp: `S_dW` and `S_db` (parameter `beta2`)\n",
    "  - Compute bias correction\n",
    "  - Update `W` and `b`  \n",
    "  \n",
    "  \n",
    "- **Parameters**:\n",
    "  - `alpha`: learning rate, to be tuned\n",
    "  - `beta1`: default `0.9` (inventors recommendation)\n",
    "  - `beta2`: default `0.999` (inventors recommendation)\n",
    "  - `Îµ`: `10^-8` (inventors recommendation, doesn't matter much, not effect on perf)  \n",
    "   \n",
    "   \n",
    "- **How does Adam work**:\n",
    "  - It calculates an exponentially weighted average of past gradients, and stores it in variables  vv  (before bias correction) and  vcorrectedvcorrected  (with bias correction).\n",
    "  - It calculates an exponentially weighted average of the squares of the past gradients, and stores it in variables  ss  (before bias correction) and  scorrectedscorrected  (with bias correction).\n",
    "  - It updates parameters in a direction based on combining information from \"1\" and \"2\"\n",
    "  \n",
    "    \n",
    "- Works well with deep learning problems and a very wide variety of architectures\n",
    "- Works with mini-batch GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/optimization-adaptive-learning-rates.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Decay\n",
    "\n",
    "= Slowly reduce the learning rate over time\n",
    "  \n",
    "   \n",
    "- **Parameters**: \n",
    "  - `alpha0`\n",
    "  - `decay_rate`\n",
    "  \n",
    "  \n",
    "- **Method 1**:\n",
    "  - `alpha0 = 0.2` and `decay_rate = 1`\n",
    "  - `alpha = (1 / (1 + decay_rate * epoch_num)) * alpha0`\n",
    "  - epoch 1: `alpha = 0.1`   \n",
    "    epoch 2: `alpha = 0.67`   \n",
    "    epoch 3: `alpha = 0.5`   \n",
    "    epoch 4: `alpha = 0.4`... \n",
    "    -> plot (alpha * epoch_num) (x, y)  \n",
    "    \n",
    "    \n",
    "- Other methods:\n",
    "  - exponential learning rate decay: `alpha = 0.95^epoch_num * alpha0`\n",
    "  - discrete staircase\n",
    "  - etc.\n",
    "  - manual decay (small number of models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local optima\n",
    "\n",
    "- bad optima\n",
    "- saddle point\n",
    "- convex or concave like functions\n",
    "- problem of plateaus = derivative close to 0 for a long time   \n",
    "  -> GD very long slow path to get off the plateau towards optimum\n",
    "  \n",
    "-> can be avoided with optimization algorithms seen before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Hyperparameter tuning*\n",
    "\n",
    "(course 2 week 3)\n",
    "  \n",
    "  \n",
    "- How to choose the sets of hyperameters to try:\n",
    "  - choose randomly, not on a grid\n",
    "  - coarse to fine:\n",
    "    - find the points that work the best in the hyperparameter space\n",
    "    - then zoom in around them (smaller zone) and generate a new more fine-grained set around them\n",
    "    - repeat?\n",
    "  - use an appropriate scale for the hyperparameters space = uniforlmy random:   \n",
    "    r = -4 * np.random()   -> 4 the number of sub-spaces: r [-4..0]\n",
    "    alpha = 10^r           -> alpha: [10^-4..10^0]\n",
    "  - sample densely with beta close to 1 (or 1 - beta close to 0)\n",
    "  - re-test your hyperparameters occasionally\n",
    "  \n",
    "  \n",
    "- When to tune your model:\n",
    "  - baby-sit the model for a while at the beginning\n",
    "  - train many models in parallel with many parameter settings and compare their learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization\n",
    "\n",
    "= normalizing activations to train `Wv` and `bv` faster   \n",
    "1.  **reduces *covariate shift***: the amount by which the distribution of the hidden unit values (activations) shift (see course 2 week 3: why does BN work?)    \n",
    "-> speeds up the learning\n",
    "2. slight **regularization effect** (see video)\n",
    "  \n",
    "  \n",
    "- in practive, we normalise `z2`   \n",
    "   is just computing the identity funtion: `z^^[i] = z^[i]`\n",
    "- mean and variance controlled by 2 explicit parameters `gamma` and `beta`\n",
    "- we don't necessarily want the features to be mean 0 and variance 1 (normal distrib)   \n",
    "  -> this normalization doesn't do that but gives fixed mean and variance   \n",
    "    \n",
    "    \n",
    "- **implementation**:   \n",
    "  - `tf.nn.batch_normalization`\n",
    "  - works with mini-batches, but   \n",
    "    **At test time**:\n",
    "    - use mean and variance computed on training mini-batches\n",
    "    - but must be applied one example at a time (see dedicated video) \n",
    "  - parameters: `b` can be eliminated, replaced by `beta_l` (see video)   \n",
    "  - **see details**: implementing gradient descent with batch-norm\n",
    "  \n",
    "  \n",
    "    1. compute `Z1` using `W1` and `b1`\n",
    "    2. apply Batch Norm (BN) with params `beta1` and `gamma1`   \n",
    "    -> normalized `Z1^` using `mu` (mean) and `sigma_square` (variance)\n",
    "    3. feed that to the activation function to get `A1`\n",
    "    4. repeat 1 to 3 for each layers\n",
    "    \n",
    "    \n",
    "- Why it works: see video (course 2 week 3) **covariate shift**\n",
    "\n",
    "<img src=\"images/batch-normalization.png\" width=\"650\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression\n",
    "\n",
    "= for multi-class classification:\n",
    "  - 'soft max' = each point in the vector has a value. [0.842, 0.042, 0.002, 0,114]\n",
    "  - 'hard max' = one value in the vector, all other are zeros. [0.842, 0, 0, 0]\n",
    "  - generalizes logistic regression to multiple classes C\n",
    "  - if C = 2 -> logistic regression (just compute the max one)\n",
    "- cf video: training a Softmax Classifier\n",
    "  - **loss function** explanation\n",
    "  - **GD with softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
