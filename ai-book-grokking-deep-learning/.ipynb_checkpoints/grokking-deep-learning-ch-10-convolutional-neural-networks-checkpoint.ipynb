{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing weights in multiple places\n",
    "\n",
    "* When you need to detect the same feature in multiple places   \n",
    "  ex. similar strokes in different parts of a digit\n",
    "  \n",
    "* Overfitting often caused by having more parameters than necessary to learn a specific dataset\n",
    "  * difficult to avoid when NNs have lots of parameters but not very many training examples\n",
    "  * regularization: a means to countering it, but not the only technique, and not most ideal\n",
    "  \n",
    "* Overfitting is about the **ratio** between:\n",
    "  * the number of weights in the model \n",
    "  * and the number of datapoints it has to learn those weights\n",
    "  \n",
    "* To avoid it, it's better to use something loosely defined as **_structure_**:   \n",
    "  * = reuse weights for multiple purposes when same pattern needs to be detected in multiple places   \n",
    "  * can significantly **reduce overfitting** and lead to much **more accurate** models\n",
    "  * because reduces weight-to-data ratio\n",
    "  \n",
    "* Usually, removing parameters makes a model less expressive (less able to learn patterns)\n",
    "  * but if you're clever in where to reuse weights\n",
    "  * model can be equally expressive and more robust to overfitting\n",
    "* Also tends to make the model smaller (fewer actual parameters to store)\n",
    "* **Convolution**: the most famous and widely spread structure in neural networks (called *convolutional layer* when used as a layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The convolutional layer\n",
    "\n",
    "* instead of a single big dense linear layer (fully-connected),   \n",
    "  lots of very small linear layers\n",
    "  * usually fewer than 25 inputs and a single output\n",
    "  * reused in every position\n",
    "  * called a convolutional **_kernel_**   \n",
    "<br/>   \n",
    "\n",
    "* **Example**: 3\\*3 convolutional kernel:\n",
    "  * predicts in its current location,\n",
    "  * moves 1 pixel to the right and predicts again\n",
    "  * and so on, until right edge reached\n",
    "  * moves down 1 pixel and predicts\n",
    "  * and so on, until bottom edge reached\n",
    "* **Result** of one kernel is a smaller matrix of kernel predictions (input to next layer)\n",
    "  * 8\\*8 image with 3\\*3 convolutional kernel: output is a 6\\*6 matrix   \n",
    "<br/>   \n",
    "\n",
    "* Convolutional layers usually have **multiple kernels**, each producing a prediction matrix:\n",
    "  * you can sum the prediction matrices elementwise = **_sum pooling_**\n",
    "  * or take the mean elementwise = **_mean pooling_**\n",
    "  * or take maximum value elementiwe = **_max pooling_** -> most popular\n",
    "  * only **final matrix** is forward propagated into next layers\n",
    "* Allows each kernel to learn a particular pattern then search for it somewhere in the image\n",
    "  * = small set of weights training over a much larger set of training examples\n",
    "  * each mini-kernel forward propagated multiple times on multiple segments of data\n",
    "  * thus changing the ratio of weights to datapoints on which those weights are being trained\n",
    "  * drastically **reduces ability to overfit** and **increases ability to generalize**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example code\n",
    "\n",
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train = x_train[0:1000], y_train[0:1000]\n",
    "num_train_images = len(x_train)\n",
    "num_test_images = len(x_test)\n",
    "\n",
    "# IMAGES\n",
    "train_images = x_train.reshape(num_train_images, 28 * 28) / 255  # shape = (1000, 784)\n",
    "test_images = x_test.reshape(num_test_images, 28*28) / 255\n",
    "\n",
    "# LABELS: one_hot vectors\n",
    "# label '4' = [0, 0, 0, 0, 1, 0, 0...]\n",
    "train_labels = np.zeros((len(y_train), 10))\n",
    "for i,l in enumerate(y_train):\n",
    "    train_labels[i][l] = 1\n",
    "\n",
    "test_labels = np.zeros((len(y_test), 10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2\n",
    "iterations = 700\n",
    "batch_size = 128\n",
    "\n",
    "pixels_per_image = 784\n",
    "num_labels = 10\n",
    "\n",
    "image_rows, image_cols = 28, 28\n",
    "kernel_rows, kernel_cols = 3, 3\n",
    "num_kernels = 16\n",
    "\n",
    "hidden_size = ( (image_rows - kernel_rows) * (image_cols - kernel_cols) ) * num_kernels   # (25*25)*16 = 10000\n",
    "kernels = 0.02 * np.random.random((kernel_rows * kernel_cols, num_kernels)) - 0.01        # shape = 9*16\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.01                    # shape = 10000*10\n",
    "\n",
    "train_acc, test_acc = 0.0, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitarian functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "tanh = lambda x: np.tanh(x)\n",
    "tanh2deriv = lambda output: 1 - (output ** 2)\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "# Convolutional kernels\n",
    "\n",
    "def get_image_section(layer, row_from, row_to, col_from, col_to):\n",
    "    '''Selects the same subregion in a batch of images.'''\n",
    "    section = layer[:,row_from:row_to,col_from:col_to]\n",
    "    section = section.reshape(-1, 1, row_to - row_from, col_to - col_from)\n",
    "    return section\n",
    "\n",
    "def get_image_sections(layer, kernel_rows, kernel_cols):\n",
    "    '''Creates a list of all the subregions in a batch of images.'''\n",
    "    sections = list()\n",
    "    n_rows = layer.shape[1]\n",
    "    n_cols = layer.shape[2]\n",
    "    \n",
    "    for row_start in range(n_rows - kernel_rows):\n",
    "        for col_start in range(n_cols - kernel_cols):\n",
    "            section = get_image_section(layer,\n",
    "                                        row_start,\n",
    "                                        row_start+kernel_rows,\n",
    "                                        col_start,\n",
    "                                        col_start+kernel_cols)\n",
    "            sections.append(section)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def expand_sections(sections):\n",
    "    '''Concatenates and reshapes the list of subregions from a batch of images.'''\n",
    "    expanded_sections = np.concatenate(sections, axis=1)\n",
    "    exp_shape = expanded_sections.shape\n",
    "    flat_sections = expanded_sections.reshape(exp_shape[0] * exp_shape[1], -1)\n",
    "    return (flat_sections, exp_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning and predicting on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0.shape (128, 28, 28)\n",
      "kernel_output.shape (80000, 16)\n",
      "exp_shape (128, 625, 3, 3) flat_sections_trn.shape (80000, 9) kernels.shape (9, 16)\n",
      "layer_1.shape (128, 10000) dropout_mask.shape (128, 10000)\n",
      "\n",
      "Iter 0 Train-Acc 0.066 Test-Acc 0.022\n",
      "Iter 20 Train-Acc 0.037 Test-Acc 0.028\n",
      "Iter 40 Train-Acc 0.191 Test-Acc 0.330\n",
      "Iter 60 Train-Acc 0.601 Test-Acc 0.795\n",
      "Iter 80 Train-Acc 0.697 Test-Acc 0.838\n",
      "Iter 100 Train-Acc 0.73 Test-Acc 0.857\n",
      "Iter 120 Train-Acc 0.77 Test-Acc 0.864\n",
      "Iter 140 Train-Acc 0.765 Test-Acc 0.870\n",
      "Iter 160 Train-Acc 0.773 Test-Acc 0.872\n",
      "Iter 180 Train-Acc 0.781 Test-Acc 0.876\n",
      "Iter 200 Train-Acc 0.79 Test-Acc 0.875\n",
      "Iter 220 Train-Acc 0.79 Test-Acc 0.876\n",
      "Iter 240 Train-Acc 0.808 Test-Acc 0.879\n",
      "Iter 260 Train-Acc 0.814 Test-Acc 0.881\n",
      "Iter 280 Train-Acc 0.815 Test-Acc 0.880\n",
      "Iter 300 Train-Acc 0.815 Test-Acc 0.88\n",
      "Iter 320 Train-Acc 0.813 Test-Acc 0.881\n",
      "Iter 340 Train-Acc 0.824 Test-Acc 0.879\n",
      "Iter 360 Train-Acc 0.832 Test-Acc 0.878\n",
      "Iter 380 Train-Acc 0.828 Test-Acc 0.877\n",
      "Iter 400 Train-Acc 0.844 Test-Acc 0.875\n",
      "Iter 420 Train-Acc 0.845 Test-Acc 0.874\n",
      "Iter 440 Train-Acc 0.837 Test-Acc 0.874\n",
      "Iter 460 Train-Acc 0.838 Test-Acc 0.872\n",
      "Iter 480 Train-Acc 0.841 Test-Acc 0.873\n",
      "Iter 500 Train-Acc 0.844 Test-Acc 0.873\n",
      "Iter 520 Train-Acc 0.839 Test-Acc 0.869\n",
      "Iter 540 Train-Acc 0.852 Test-Acc 0.872\n",
      "Iter 560 Train-Acc 0.853 Test-Acc 0.873\n",
      "Iter 580 Train-Acc 0.854 Test-Acc 0.873\n",
      "Iter 600 Train-Acc 0.838 Test-Acc 0.872\n",
      "Iter 620 Train-Acc 0.846 Test-Acc 0.871\n",
      "Iter 640 Train-Acc 0.839 Test-Acc 0.870\n",
      "Iter 660 Train-Acc 0.852 Test-Acc 0.867\n",
      "Iter 680 Train-Acc 0.851 Test-Acc 0.870\n",
      "Iter 699 Train-Acc 0.851 Test-Acc 0.869\n"
     ]
    }
   ],
   "source": [
    "for j in range(iterations):\n",
    "    \n",
    "    # LEARNING AND PREDICTING ON TRAINING DATA\n",
    "    \n",
    "    train_correct_cnt = 0\n",
    "    \n",
    "    for i in range(num_train_images // batch_size):\n",
    "        batch_start, batch_end = (i * batch_size), ((i+1) * batch_size)\n",
    "        \n",
    "        # LAYER 0\n",
    "        layer_0 = train_images[batch_start:batch_end]         # shape = (28, 28)\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)   # shape = (128, 28, 28)\n",
    "        \n",
    "        # exp_shape = (128, 1875, 3) - flat_sections_trn.shape = (240000, 3) - kernels.shape = (9, 16)\n",
    "        trn_sections = get_image_sections(layer_0, kernel_rows, kernel_cols)\n",
    "        (flat_sections_trn, exp_shape) = expand_sections(trn_sections)\n",
    "        kernel_output = flat_sections_trn.dot(kernels)  # set of 2-dim images (output of each kernel in each image position)\n",
    "        \n",
    "        # LAYER 1\n",
    "        layer_1 = tanh(kernel_output.reshape(exp_shape[0], -1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        \n",
    "        # LAYER 2\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            target_labels = train_labels[batch_start+k:batch_start+k+1]\n",
    "            train_correct_cnt += int( np.argmax(layer_2[k:k+1]) == np.argmax(target_labels) )\n",
    "        train_acc = train_correct_cnt / float(num_train_images)\n",
    "        \n",
    "        layer_2_delta = (train_labels[batch_start:batch_end] - layer_2) / (batch_size * layer_2.shape[0])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        l1d_reshape = layer_1_delta.reshape(kernel_output.shape)\n",
    "        k_update = flat_sections_trn.T.dot(l1d_reshape)\n",
    "        kernels -= alpha * k_update\n",
    "        \n",
    "        if (j == 0) and (i == 0):\n",
    "            print(f'layer_0.shape {layer_0.shape}')   # (128, 28, 28)\n",
    "            print(f'kernel_output.shape {kernel_output.shape}')  \n",
    "            print('exp_shape {} flat_sections_trn.shape {} kernels.shape {}'.format(exp_shape,\n",
    "                                                                                    flat_sections_trn.shape,\n",
    "                                                                                    kernels.shape))\n",
    "            print('layer_1.shape {} dropout_mask.shape {}'.format(layer_1.shape,     # (128, 10000)\n",
    "                                                              dropout_mask.shape))   # (128, 10000)\n",
    "            print()\n",
    "    \n",
    "    # LEARNING AND PREDICTING ON TEST DATA\n",
    "    \n",
    "    test_correct_cnt = 0\n",
    "    \n",
    "    for m in range(num_test_images):\n",
    "        \n",
    "        # LAYER 0\n",
    "        layer_0 = test_images[m:m+1]\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
    "        layer_0.shape\n",
    "        \n",
    "        tst_sections = get_image_sections(layer_0, kernel_rows, kernel_cols)\n",
    "        (flat_sections_tst, exp_shape) = expand_sections(tst_sections)\n",
    "        kernel_output = flat_sections_tst.dot(kernels)\n",
    "        \n",
    "        # LAYER 1\n",
    "        layer_1 = tanh(kernel_output.reshape(exp_shape[0], -1))\n",
    "        \n",
    "        # LAYER 2\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        test_correct_cnt += int( np.argmax(layer_2) == np.argmax(test_labels[m:m+1]) )\n",
    "        test_acc = test_correct_cnt / float(num_test_images)\n",
    "    \n",
    "    if (j % 20 == 0) or (j == iterations-1):\n",
    "        print('Iter ' + str(j) + ' Train-Acc ' + str(train_acc)[0:5] + ' Test-Acc ' + str(test_acc)[0:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we use one layer for all convolutions,   \n",
    "  but most convolutions stack multiple stacked layers:   \n",
    "  * each convolutional layer treats the previous layers as an image\n",
    "  * one of the main developments that allowed very deep neural networks (and the popularization of the phrase **_deep learning_**)\n",
    "  * a **landmark** in the field and major progress!  \n",
    "<br/>   \n",
    "\n",
    "* Independently learning different types of information in different sets of weights (instead of all together),\n",
    "  * for ex. image of a cat = colors, lines and edges, corners, small shapes\n",
    "  * sets of **lower-level features**\n",
    "* Then combining the different types of low-level features that correspond to the output   \n",
    "  \n",
    "<p style=\"background:#DDEEEE; padding: 15px; border-left: 7px solid red;\">\n",
    "Using the same piece of intelligence, and the <b>same weights</b>, in multiple places:  \n",
    "<br/>    \n",
    "makes the <b>weights more intelligent</b> by giving them more samples to learn from, <b>increasing generalization</b>\n",
    "</p>\n",
    "\n",
    "* Many of the biggest developments in deep learning over the past five years are iterations of this idea:\n",
    "    * convolutions\n",
    "    * recurrent neural networks (RNNs)\n",
    "    * word embeddings\n",
    "    * capsule networks\n",
    "\n",
    "* When you know a network will need the same idea in multiple places, force it to use the same weights in those places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
